{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Training Deep Neural Networks**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import tensorflow as tf\n",
                "from tensorflow import keras"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Vanishing/Exploding Gradients Problem\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "def logit(z):\n",
                "    return 1 / (1 + np.exp(-z))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 432x288 with 1 Axes>"
                        ]
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": [
                "z = np.linspace(-5, 5, 200)\n",
                "\n",
                "plt.plot([-5, 5], [0, 0], 'k-')\n",
                "plt.plot([-5, 5], [1, 1], 'k--')\n",
                "plt.plot([0, 0], [-0.2, 1.2], 'k-')\n",
                "plt.plot([-5, 5], [-3 / 4, 7 / 4], 'g--')\n",
                "plt.plot(z, logit(z), \"b-\", linewidth=2)\n",
                "props = dict(facecolor='black', shrink=0.1)\n",
                "plt.annotate('Saturating',\n",
                "             xytext=(3.5, 0.7),\n",
                "             xy=(5, 1),\n",
                "             arrowprops=props,\n",
                "             fontsize=14,\n",
                "             ha=\"center\")\n",
                "plt.annotate('Saturating',\n",
                "             xytext=(-3.5, 0.3),\n",
                "             xy=(-5, 0),\n",
                "             arrowprops=props,\n",
                "             fontsize=14,\n",
                "             ha=\"center\")\n",
                "plt.annotate('Linear',\n",
                "             xytext=(2, 0.2),\n",
                "             xy=(0, 0.5),\n",
                "             arrowprops=props,\n",
                "             fontsize=14,\n",
                "             ha=\"center\")\n",
                "plt.grid(True)\n",
                "plt.title(\"Sigmoid activation function\", fontsize=14)\n",
                "plt.axis([-5, 5, -0.2, 1.2])\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Xavier and He Initialization\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "['Constant',\n",
                            " 'GlorotNormal',\n",
                            " 'GlorotUniform',\n",
                            " 'HeNormal',\n",
                            " 'HeUniform',\n",
                            " 'Identity',\n",
                            " 'Initializer',\n",
                            " 'LecunNormal',\n",
                            " 'LecunUniform',\n",
                            " 'Ones',\n",
                            " 'Orthogonal',\n",
                            " 'RandomNormal',\n",
                            " 'RandomUniform',\n",
                            " 'TruncatedNormal',\n",
                            " 'VarianceScaling',\n",
                            " 'Zeros',\n",
                            " 'constant',\n",
                            " 'deserialize',\n",
                            " 'get',\n",
                            " 'glorot_normal',\n",
                            " 'glorot_uniform',\n",
                            " 'he_normal',\n",
                            " 'he_uniform',\n",
                            " 'identity',\n",
                            " 'lecun_normal',\n",
                            " 'lecun_uniform',\n",
                            " 'ones',\n",
                            " 'orthogonal',\n",
                            " 'random_normal',\n",
                            " 'random_uniform',\n",
                            " 'serialize',\n",
                            " 'truncated_normal',\n",
                            " 'variance_scaling',\n",
                            " 'zeros']"
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "[name for name in dir(keras.initializers) if not name.startswith(\"_\")]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<keras.layers.core.dense.Dense at 0x1699e2530>"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "keras.layers.Dense(10, activation=\"relu\", kernel_initializer=\"he_normal\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<keras.layers.core.dense.Dense at 0x169ce40a0>"
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "init = keras.initializers.VarianceScaling(scale=2.,\n",
                "                                          mode='fan_avg',\n",
                "                                          distribution='uniform')\n",
                "keras.layers.Dense(10, activation=\"relu\", kernel_initializer=init)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Nonsaturating Activation Functions\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Leaky ReLU\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "def leaky_relu(z, alpha=0.01):\n",
                "    return np.maximum(alpha * z, z)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 432x288 with 1 Axes>"
                        ]
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": [
                "plt.plot(z, leaky_relu(z, 0.05), \"b-\", linewidth=2)\n",
                "plt.plot([-5, 5], [0, 0], 'k-')\n",
                "plt.plot([0, 0], [-0.5, 4.2], 'k-')\n",
                "plt.grid(True)\n",
                "props = dict(facecolor='black', shrink=0.1)\n",
                "plt.annotate('Leak',\n",
                "             xytext=(-3.5, 0.5),\n",
                "             xy=(-5, -0.2),\n",
                "             arrowprops=props,\n",
                "             fontsize=14,\n",
                "             ha=\"center\")\n",
                "plt.title(\"Leaky ReLU activation function\", fontsize=14)\n",
                "plt.axis([-5, 5, -0.5, 4.2])\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "['deserialize',\n",
                            " 'elu',\n",
                            " 'exponential',\n",
                            " 'gelu',\n",
                            " 'get',\n",
                            " 'hard_sigmoid',\n",
                            " 'linear',\n",
                            " 'relu',\n",
                            " 'selu',\n",
                            " 'serialize',\n",
                            " 'sigmoid',\n",
                            " 'softmax',\n",
                            " 'softplus',\n",
                            " 'softsign',\n",
                            " 'swish',\n",
                            " 'tanh']"
                        ]
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "[m for m in dir(keras.activations) if not m.startswith(\"_\")]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "['LeakyReLU', 'PReLU', 'ReLU', 'ThresholdedReLU']"
                        ]
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "[m for m in dir(keras.layers) if \"relu\" in m.lower()]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's train a neural network on Fashion MNIST using the Leaky ReLU:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "# (X_train_full,\n",
                "#  y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
                "# np.savez(file=\"../../data-handson/fashion_mnist_X.npz\",train=X_train_full, test=X_test)\n",
                "# np.savez(file=\"../../data-handson/fashion_mnist_y.npz\",train=y_train_full, test=y_test)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "X = np.load(file=\"../../data-handson/fashion_mnist_X.npz\")\n",
                "y = np.load(file=\"../../data-handson/fashion_mnist_y.npz\")\n",
                "X_train_full, X_test = X[\"train\"], X[\"test\"]\n",
                "y_train_full, y_test = y[\"train\"], y[\"test\"]\n",
                "X_train_full = X_train_full / 255.0\n",
                "X_test = X_test / 255.0\n",
                "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
                "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "tf.random.set_seed(42)\n",
                "np.random.seed(42)\n",
                "\n",
                "model = keras.models.Sequential([\n",
                "    keras.layers.Flatten(input_shape=[28, 28]),\n",
                "    keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
                "    keras.layers.LeakyReLU(),\n",
                "    keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
                "    keras.layers.LeakyReLU(),\n",
                "    keras.layers.Dense(10, activation=\"softmax\")\n",
                "])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
                "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
                "              metrics=[\"accuracy\"])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {
                "scrolled": true
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2022-03-11 16:13:44.896866: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/10\n",
                        "1719/1719 [==============================] - 7s 4ms/step - loss: 1.2819 - accuracy: 0.6229 - val_loss: 0.8886 - val_accuracy: 0.7160\n",
                        "Epoch 2/10\n",
                        "1719/1719 [==============================] - 6s 4ms/step - loss: 0.7955 - accuracy: 0.7362 - val_loss: 0.7130 - val_accuracy: 0.7656\n",
                        "Epoch 3/10\n",
                        "1719/1719 [==============================] - 6s 3ms/step - loss: 0.6816 - accuracy: 0.7721 - val_loss: 0.6427 - val_accuracy: 0.7898\n",
                        "Epoch 4/10\n",
                        "1719/1719 [==============================] - 6s 4ms/step - loss: 0.6217 - accuracy: 0.7944 - val_loss: 0.5900 - val_accuracy: 0.8066\n",
                        "Epoch 5/10\n",
                        "1719/1719 [==============================] - 7s 4ms/step - loss: 0.5832 - accuracy: 0.8075 - val_loss: 0.5582 - val_accuracy: 0.8198\n",
                        "Epoch 6/10\n",
                        "1719/1719 [==============================] - 7s 4ms/step - loss: 0.5553 - accuracy: 0.8156 - val_loss: 0.5350 - val_accuracy: 0.8238\n",
                        "Epoch 7/10\n",
                        "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5338 - accuracy: 0.8224 - val_loss: 0.5156 - val_accuracy: 0.8304\n",
                        "Epoch 8/10\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5173 - accuracy: 0.8272 - val_loss: 0.5079 - val_accuracy: 0.8284\n",
                        "Epoch 9/10\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5040 - accuracy: 0.8289 - val_loss: 0.4895 - val_accuracy: 0.8386\n",
                        "Epoch 10/10\n",
                        "1719/1719 [==============================] - 4s 3ms/step - loss: 0.4924 - accuracy: 0.8320 - val_loss: 0.4817 - val_accuracy: 0.8396\n"
                    ]
                }
            ],
            "source": [
                "history = model.fit(X_train,\n",
                "                    y_train,\n",
                "                    epochs=10,\n",
                "                    validation_data=(X_valid, y_valid))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now let's try PReLU:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": [
                "tf.random.set_seed(42)\n",
                "np.random.seed(42)\n",
                "\n",
                "model = keras.models.Sequential([\n",
                "    keras.layers.Flatten(input_shape=[28, 28]),\n",
                "    keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
                "    keras.layers.PReLU(),\n",
                "    keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
                "    keras.layers.PReLU(),\n",
                "    keras.layers.Dense(10, activation=\"softmax\")\n",
                "])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
                "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
                "              metrics=[\"accuracy\"])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/10\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 1.3461 - accuracy: 0.6209 - val_loss: 0.9255 - val_accuracy: 0.7186\n",
                        "Epoch 2/10\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.8197 - accuracy: 0.7356 - val_loss: 0.7305 - val_accuracy: 0.7628\n",
                        "Epoch 3/10\n",
                        "1719/1719 [==============================] - 4s 3ms/step - loss: 0.6966 - accuracy: 0.7693 - val_loss: 0.6565 - val_accuracy: 0.7878\n",
                        "Epoch 4/10\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6331 - accuracy: 0.7909 - val_loss: 0.6004 - val_accuracy: 0.8046\n",
                        "Epoch 5/10\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5917 - accuracy: 0.8057 - val_loss: 0.5656 - val_accuracy: 0.8180\n",
                        "Epoch 6/10\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5618 - accuracy: 0.8135 - val_loss: 0.5406 - val_accuracy: 0.8238\n",
                        "Epoch 7/10\n",
                        "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5390 - accuracy: 0.8205 - val_loss: 0.5196 - val_accuracy: 0.8312\n",
                        "Epoch 8/10\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5213 - accuracy: 0.8257 - val_loss: 0.5113 - val_accuracy: 0.8318\n",
                        "Epoch 9/10\n",
                        "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5070 - accuracy: 0.8288 - val_loss: 0.4916 - val_accuracy: 0.8378\n",
                        "Epoch 10/10\n",
                        "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4945 - accuracy: 0.8316 - val_loss: 0.4826 - val_accuracy: 0.8398\n"
                    ]
                }
            ],
            "source": [
                "history = model.fit(X_train,\n",
                "                    y_train,\n",
                "                    epochs=10,\n",
                "                    validation_data=(X_valid, y_valid))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ELU\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [],
            "source": [
                "def elu(z, alpha=1):\n",
                "    return np.where(z < 0, alpha * (np.exp(z) - 1), z)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 432x288 with 1 Axes>"
                        ]
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": [
                "plt.plot(z, elu(z), \"b-\", linewidth=2)\n",
                "plt.plot([-5, 5], [0, 0], 'k-')\n",
                "plt.plot([-5, 5], [-1, -1], 'k--')\n",
                "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
                "plt.grid(True)\n",
                "plt.title(r\"ELU activation function ($\\alpha=1$)\", fontsize=14)\n",
                "plt.axis([-5, 5, -2.2, 3.2])\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Implementing ELU in TensorFlow is trivial, just specify the activation function when building each layer:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<keras.layers.core.dense.Dense at 0x17b4568c0>"
                        ]
                    },
                    "execution_count": 21,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "keras.layers.Dense(10, activation=\"elu\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### SELU\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This activation function was proposed in this [great paper](https://arxiv.org/pdf/1706.02515.pdf) by Günter Klambauer, Thomas Unterthiner and Andreas Mayr, published in June 2017. During training, a neural network composed exclusively of a stack of dense layers using the SELU activation function and LeCun initialization will self-normalize: the output of each layer will tend to preserve the same mean and variance during training, which solves the vanishing/exploding gradients problem. As a result, this activation function outperforms the other activation functions very significantly for such neural nets, so you should really try it out. Unfortunately, the self-normalizing property of the SELU activation function is easily broken: you cannot use ℓ<sub>1</sub> or ℓ<sub>2</sub> regularization, regular dropout, max-norm, skip connections or other non-sequential topologies (so recurrent neural networks won't self-normalize). However, in practice it works quite well with sequential CNNs. If you break self-normalization, SELU will not necessarily outperform other activation functions.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [],
            "source": [
                "from scipy.special import erfc\n",
                "\n",
                "# alpha and scale to self normalize with mean 0 and standard deviation 1\n",
                "# (see equation 14 in the paper):\n",
                "alpha_0_1 = -np.sqrt(2 / np.pi) / (erfc(1 / np.sqrt(2)) * np.exp(1 / 2) - 1)\n",
                "scale_0_1 = (1 - erfc(1 / np.sqrt(2)) * np.sqrt(np.e)) * np.sqrt(2 * np.pi) * (\n",
                "    2 * erfc(np.sqrt(2)) * np.e**2 + np.pi * erfc(1 / np.sqrt(2))**2 * np.e -\n",
                "    2 *\n",
                "    (2 + np.pi) * erfc(1 / np.sqrt(2)) * np.sqrt(np.e) + np.pi + 2)**(-1 / 2)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [],
            "source": [
                "def selu(z, scale=scale_0_1, alpha=alpha_0_1):\n",
                "    return scale * elu(z, alpha)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 432x288 with 1 Axes>"
                        ]
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": [
                "plt.plot(z, selu(z), \"b-\", linewidth=2)\n",
                "plt.plot([-5, 5], [0, 0], 'k-')\n",
                "plt.plot([-5, 5], [-1.758, -1.758], 'k--')\n",
                "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
                "plt.grid(True)\n",
                "plt.title(\"SELU activation function\", fontsize=14)\n",
                "plt.axis([-5, 5, -2.2, 3.2])\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "By default, the SELU hyperparameters (`scale` and `alpha`) are tuned in such a way that the mean output of each neuron remains close to 0, and the standard deviation remains close to 1 (assuming the inputs are standardized with mean 0 and standard deviation 1 too). Using this activation function, even a 1,000 layer deep neural network preserves roughly mean 0 and standard deviation 1 across all layers, avoiding the exploding/vanishing gradients problem:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Layer 0: mean -0.00, std deviation 1.00\n",
                        "Layer 100: mean 0.02, std deviation 0.96\n",
                        "Layer 200: mean 0.01, std deviation 0.90\n",
                        "Layer 300: mean -0.02, std deviation 0.92\n",
                        "Layer 400: mean 0.05, std deviation 0.89\n",
                        "Layer 500: mean 0.01, std deviation 0.93\n",
                        "Layer 600: mean 0.02, std deviation 0.92\n",
                        "Layer 700: mean -0.02, std deviation 0.90\n",
                        "Layer 800: mean 0.05, std deviation 0.83\n",
                        "Layer 900: mean 0.02, std deviation 1.00\n"
                    ]
                }
            ],
            "source": [
                "np.random.seed(42)\n",
                "Z = np.random.normal(size=(500, 100))  # standardized inputs\n",
                "for layer in range(1000):\n",
                "    W = np.random.normal(size=(100, 100),\n",
                "                         scale=np.sqrt(1 / 100))  # LeCun initialization\n",
                "    Z = selu(np.dot(Z, W))\n",
                "    means = np.mean(Z, axis=0).mean()\n",
                "    stds = np.std(Z, axis=0).mean()\n",
                "    if layer % 100 == 0:\n",
                "        print(\"Layer {}: mean {:.2f}, std deviation {:.2f}\".format(\n",
                "            layer, means, stds))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Using SELU is easy:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<keras.layers.core.dense.Dense at 0x17ccdc2b0>"
                        ]
                    },
                    "execution_count": 27,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "keras.layers.Dense(10, activation=\"selu\", kernel_initializer=\"lecun_normal\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's create a neural net for Fashion MNIST with 100 hidden layers, using the SELU activation function:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [],
            "source": [
                "np.random.seed(42)\n",
                "tf.random.set_seed(42)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = keras.models.Sequential()\n",
                "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
                "model.add(\n",
                "    keras.layers.Dense(300,\n",
                "                       activation=\"selu\",\n",
                "                       kernel_initializer=\"lecun_normal\"))\n",
                "for layer in range(99):\n",
                "    model.add(\n",
                "        keras.layers.Dense(100,\n",
                "                           activation=\"selu\",\n",
                "                           kernel_initializer=\"lecun_normal\"))\n",
                "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
                "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
                "              metrics=[\"accuracy\"])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now let's train it. Do not forget to scale the inputs to mean 0 and standard deviation 1:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [],
            "source": [
                "pixel_means = X_train.mean(axis=0, keepdims=True)\n",
                "pixel_stds = X_train.std(axis=0, keepdims=True)\n",
                "X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
                "X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
                "X_test_scaled = (X_test - pixel_means) / pixel_stds"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/5\n",
                        "1719/1719 [==============================] - 28s 15ms/step - loss: 1.1658 - accuracy: 0.5572 - val_loss: 0.7362 - val_accuracy: 0.7492\n",
                        "Epoch 2/5\n",
                        "1719/1719 [==============================] - 28s 16ms/step - loss: 0.7124 - accuracy: 0.7435 - val_loss: 0.6097 - val_accuracy: 0.7848\n",
                        "Epoch 3/5\n",
                        "1719/1719 [==============================] - 27s 16ms/step - loss: 0.6053 - accuracy: 0.7821 - val_loss: 0.5891 - val_accuracy: 0.7806\n",
                        "Epoch 4/5\n",
                        "1719/1719 [==============================] - 27s 16ms/step - loss: 0.5503 - accuracy: 0.8063 - val_loss: 0.5160 - val_accuracy: 0.8200\n",
                        "Epoch 5/5\n",
                        "1719/1719 [==============================] - 28s 16ms/step - loss: 0.5016 - accuracy: 0.8231 - val_loss: 0.4691 - val_accuracy: 0.8380\n"
                    ]
                }
            ],
            "source": [
                "history = model.fit(X_train_scaled,\n",
                "                    y_train,\n",
                "                    epochs=5,\n",
                "                    validation_data=(X_valid_scaled, y_valid))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now look at what happens if we try to use the ReLU activation function instead:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "metadata": {},
            "outputs": [],
            "source": [
                "np.random.seed(42)\n",
                "tf.random.set_seed(42)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = keras.models.Sequential()\n",
                "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
                "model.add(\n",
                "    keras.layers.Dense(300, activation=\"relu\", kernel_initializer=\"he_normal\"))\n",
                "for layer in range(99):\n",
                "    model.add(\n",
                "        keras.layers.Dense(100,\n",
                "                           activation=\"relu\",\n",
                "                           kernel_initializer=\"he_normal\"))\n",
                "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
                "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
                "              metrics=[\"accuracy\"])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/5\n",
                        "1719/1719 [==============================] - 17s 9ms/step - loss: 1.8219 - accuracy: 0.2501 - val_loss: 1.4374 - val_accuracy: 0.3758\n",
                        "Epoch 2/5\n",
                        "1719/1719 [==============================] - 20s 12ms/step - loss: 1.1882 - accuracy: 0.5012 - val_loss: 0.9614 - val_accuracy: 0.6194\n",
                        "Epoch 3/5\n",
                        "1719/1719 [==============================] - 20s 11ms/step - loss: 0.9784 - accuracy: 0.6036 - val_loss: 1.0107 - val_accuracy: 0.5256\n",
                        "Epoch 4/5\n",
                        "1719/1719 [==============================] - 19s 11ms/step - loss: 0.8797 - accuracy: 0.6521 - val_loss: 0.8039 - val_accuracy: 0.6452\n",
                        "Epoch 5/5\n",
                        "1719/1719 [==============================] - 19s 11ms/step - loss: 0.8647 - accuracy: 0.6606 - val_loss: 0.7879 - val_accuracy: 0.6912\n"
                    ]
                }
            ],
            "source": [
                "history = model.fit(X_train_scaled,\n",
                "                    y_train,\n",
                "                    epochs=5,\n",
                "                    validation_data=(X_valid_scaled, y_valid))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Not great at all, we suffered from the vanishing/exploding gradients problem.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Batch Normalization\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = keras.models.Sequential([\n",
                "    keras.layers.Flatten(input_shape=[28, 28]),\n",
                "    keras.layers.BatchNormalization(),\n",
                "    keras.layers.Dense(300, activation=\"relu\"),\n",
                "    keras.layers.BatchNormalization(),\n",
                "    keras.layers.Dense(100, activation=\"relu\"),\n",
                "    keras.layers.BatchNormalization(),\n",
                "    keras.layers.Dense(10, activation=\"softmax\")\n",
                "])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Model: \"sequential_4\"\n",
                        "_________________________________________________________________\n",
                        " Layer (type)                Output Shape              Param #   \n",
                        "=================================================================\n",
                        " flatten_4 (Flatten)         (None, 784)               0         \n",
                        "                                                                 \n",
                        " batch_normalization (BatchN  (None, 784)              3136      \n",
                        " ormalization)                                                   \n",
                        "                                                                 \n",
                        " dense_212 (Dense)           (None, 300)               235500    \n",
                        "                                                                 \n",
                        " batch_normalization_1 (Batc  (None, 300)              1200      \n",
                        " hNormalization)                                                 \n",
                        "                                                                 \n",
                        " dense_213 (Dense)           (None, 100)               30100     \n",
                        "                                                                 \n",
                        " batch_normalization_2 (Batc  (None, 100)              400       \n",
                        " hNormalization)                                                 \n",
                        "                                                                 \n",
                        " dense_214 (Dense)           (None, 10)                1010      \n",
                        "                                                                 \n",
                        "=================================================================\n",
                        "Total params: 271,346\n",
                        "Trainable params: 268,978\n",
                        "Non-trainable params: 2,368\n",
                        "_________________________________________________________________\n"
                    ]
                }
            ],
            "source": [
                "model.summary()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[('batch_normalization/gamma:0', True),\n",
                            " ('batch_normalization/beta:0', True),\n",
                            " ('batch_normalization/moving_mean:0', False),\n",
                            " ('batch_normalization/moving_variance:0', False)]"
                        ]
                    },
                    "execution_count": 39,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "bn1 = model.layers[1]\n",
                "[(var.name, var.trainable) for var in bn1.variables]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "metadata": {},
            "outputs": [],
            "source": [
                "#bn1.updates #deprecated"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
                "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
                "              metrics=[\"accuracy\"])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/10\n",
                        "1719/1719 [==============================] - 6s 3ms/step - loss: 0.8750 - accuracy: 0.7123 - val_loss: 0.5526 - val_accuracy: 0.8230\n",
                        "Epoch 2/10\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5753 - accuracy: 0.8032 - val_loss: 0.4725 - val_accuracy: 0.8472\n",
                        "Epoch 3/10\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5190 - accuracy: 0.8204 - val_loss: 0.4376 - val_accuracy: 0.8554\n",
                        "Epoch 4/10\n",
                        "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4827 - accuracy: 0.8323 - val_loss: 0.4152 - val_accuracy: 0.8596\n",
                        "Epoch 5/10\n",
                        "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4565 - accuracy: 0.8406 - val_loss: 0.3998 - val_accuracy: 0.8636\n",
                        "Epoch 6/10\n",
                        "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4398 - accuracy: 0.8473 - val_loss: 0.3867 - val_accuracy: 0.8698\n",
                        "Epoch 7/10\n",
                        "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4242 - accuracy: 0.8513 - val_loss: 0.3764 - val_accuracy: 0.8698\n",
                        "Epoch 8/10\n",
                        "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4144 - accuracy: 0.8541 - val_loss: 0.3713 - val_accuracy: 0.8736\n",
                        "Epoch 9/10\n",
                        "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4024 - accuracy: 0.8581 - val_loss: 0.3633 - val_accuracy: 0.8756\n",
                        "Epoch 10/10\n",
                        "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3914 - accuracy: 0.8623 - val_loss: 0.3574 - val_accuracy: 0.8760\n"
                    ]
                }
            ],
            "source": [
                "history = model.fit(X_train,\n",
                "                    y_train,\n",
                "                    epochs=10,\n",
                "                    validation_data=(X_valid, y_valid))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Sometimes applying BN before the activation function works better (there's a debate on this topic). Moreover, the layer before a `BatchNormalization` layer does not need to have bias terms, since the `BatchNormalization` layer has some as well, it would be a waste of parameters, so you can set `use_bias=False` when creating those layers:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 43,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = keras.models.Sequential([\n",
                "    keras.layers.Flatten(input_shape=[28, 28]),\n",
                "    keras.layers.BatchNormalization(),\n",
                "    keras.layers.Dense(300, use_bias=False),\n",
                "    keras.layers.BatchNormalization(),\n",
                "    keras.layers.Activation(\"relu\"),\n",
                "    keras.layers.Dense(100, use_bias=False),\n",
                "    keras.layers.BatchNormalization(),\n",
                "    keras.layers.Activation(\"relu\"),\n",
                "    keras.layers.Dense(10, activation=\"softmax\")\n",
                "])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 44,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
                "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
                "              metrics=[\"accuracy\"])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 45,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/10\n",
                        "1719/1719 [==============================] - 7s 4ms/step - loss: 1.0317 - accuracy: 0.6757 - val_loss: 0.6767 - val_accuracy: 0.7810\n",
                        "Epoch 2/10\n",
                        "1719/1719 [==============================] - 7s 4ms/step - loss: 0.6790 - accuracy: 0.7793 - val_loss: 0.5566 - val_accuracy: 0.8180\n",
                        "Epoch 3/10\n",
                        "1719/1719 [==============================] - 8s 5ms/step - loss: 0.5960 - accuracy: 0.8037 - val_loss: 0.5007 - val_accuracy: 0.8362\n",
                        "Epoch 4/10\n",
                        "1719/1719 [==============================] - 7s 4ms/step - loss: 0.5447 - accuracy: 0.8192 - val_loss: 0.4666 - val_accuracy: 0.8448\n",
                        "Epoch 5/10\n",
                        "1719/1719 [==============================] - 7s 4ms/step - loss: 0.5109 - accuracy: 0.8278 - val_loss: 0.4433 - val_accuracy: 0.8536\n",
                        "Epoch 6/10\n",
                        "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4898 - accuracy: 0.8339 - val_loss: 0.4263 - val_accuracy: 0.8548\n",
                        "Epoch 7/10\n",
                        "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4712 - accuracy: 0.8397 - val_loss: 0.4130 - val_accuracy: 0.8568\n",
                        "Epoch 8/10\n",
                        "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4560 - accuracy: 0.8441 - val_loss: 0.4034 - val_accuracy: 0.8608\n",
                        "Epoch 9/10\n",
                        "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4441 - accuracy: 0.8474 - val_loss: 0.3943 - val_accuracy: 0.8638\n",
                        "Epoch 10/10\n",
                        "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4333 - accuracy: 0.8504 - val_loss: 0.3874 - val_accuracy: 0.8658\n"
                    ]
                }
            ],
            "source": [
                "history = model.fit(X_train,\n",
                "                    y_train,\n",
                "                    epochs=10,\n",
                "                    validation_data=(X_valid, y_valid))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Gradient Clipping\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "All Keras optimizers accept `clipnorm` or `clipvalue` arguments:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 46,
            "metadata": {},
            "outputs": [],
            "source": [
                "optimizer = keras.optimizers.SGD(clipvalue=1.0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 47,
            "metadata": {},
            "outputs": [],
            "source": [
                "optimizer = keras.optimizers.SGD(clipnorm=1.0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Reusing Pretrained Layers\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Reusing a Keras model\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's split the fashion MNIST training set in two:\n",
                "\n",
                "- `X_train_A`: all images of all items except for sandals and shirts (classes 5 and 6).\n",
                "- `X_train_B`: a much smaller training set of just the first 200 images of sandals or shirts.\n",
                "\n",
                "The validation set and the test set are also split this way, but without restricting the number of images.\n",
                "\n",
                "We will train a model on set A (classification task with 8 classes), and try to reuse it to tackle set B (binary classification). We hope to transfer a little bit of knowledge from task A to task B, since classes in set A (sneakers, ankle boots, coats, t-shirts, etc.) are somewhat similar to classes in set B (sandals and shirts). However, since we are using `Dense` layers, only patterns that occur at the same location can be reused (in contrast, convolutional layers will transfer much better, since learned patterns can be detected anywhere on the image, as we will see in the CNN chapter).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 48,
            "metadata": {},
            "outputs": [],
            "source": [
                "def split_dataset(X, y):\n",
                "    y_5_or_6 = (y == 5) | (y == 6)  # sandals or shirts\n",
                "    y_A = y[~y_5_or_6]\n",
                "    y_A[y_A > 6] -= 2  # class indices 7, 8, 9 should be moved to 5, 6, 7\n",
                "    y_B = (y[y_5_or_6] == 6).astype(\n",
                "        np.float32)  # binary classification task: is it a shirt (class 6)?\n",
                "    return ((X[~y_5_or_6], y_A), (X[y_5_or_6], y_B))\n",
                "\n",
                "\n",
                "(X_train_A, y_train_A), (X_train_B,\n",
                "                         y_train_B) = split_dataset(X_train, y_train)\n",
                "(X_valid_A, y_valid_A), (X_valid_B,\n",
                "                         y_valid_B) = split_dataset(X_valid, y_valid)\n",
                "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
                "X_train_B = X_train_B[:200]\n",
                "y_train_B = y_train_B[:200]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 49,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(43986, 28, 28)"
                        ]
                    },
                    "execution_count": 49,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "X_train_A.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 50,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(200, 28, 28)"
                        ]
                    },
                    "execution_count": 50,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "X_train_B.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 51,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "array([4, 0, 5, 7, 7, 7, 4, 4, 3, 4, 0, 1, 6, 3, 4, 3, 2, 6, 5, 3, 4, 5,\n",
                            "       1, 3, 4, 2, 0, 6, 7, 1], dtype=uint8)"
                        ]
                    },
                    "execution_count": 51,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "y_train_A[:30]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 52,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "array([1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
                            "       0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.], dtype=float32)"
                        ]
                    },
                    "execution_count": 52,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "y_train_B[:30]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 53,
            "metadata": {},
            "outputs": [],
            "source": [
                "tf.random.set_seed(42)\n",
                "np.random.seed(42)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 54,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_A = keras.models.Sequential()\n",
                "model_A.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
                "for n_hidden in (300, 100, 50, 50, 50):\n",
                "    model_A.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
                "model_A.add(keras.layers.Dense(8, activation=\"softmax\"))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 55,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
                "                optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
                "                metrics=[\"accuracy\"])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 56,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/20\n",
                        "1375/1375 [==============================] - 3s 2ms/step - loss: 0.5926 - accuracy: 0.8104 - val_loss: 0.3896 - val_accuracy: 0.8662\n",
                        "Epoch 2/20\n",
                        "1375/1375 [==============================] - 2s 2ms/step - loss: 0.3523 - accuracy: 0.8785 - val_loss: 0.3288 - val_accuracy: 0.8824\n",
                        "Epoch 3/20\n",
                        "1375/1375 [==============================] - 2s 2ms/step - loss: 0.3171 - accuracy: 0.8896 - val_loss: 0.3014 - val_accuracy: 0.8979\n",
                        "Epoch 4/20\n",
                        "1375/1375 [==============================] - 4s 3ms/step - loss: 0.2973 - accuracy: 0.8974 - val_loss: 0.2894 - val_accuracy: 0.9023\n",
                        "Epoch 5/20\n",
                        "1375/1375 [==============================] - 4s 3ms/step - loss: 0.2835 - accuracy: 0.9021 - val_loss: 0.2776 - val_accuracy: 0.9071\n",
                        "Epoch 6/20\n",
                        "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2730 - accuracy: 0.9060 - val_loss: 0.2733 - val_accuracy: 0.9071\n",
                        "Epoch 7/20\n",
                        "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2642 - accuracy: 0.9090 - val_loss: 0.2718 - val_accuracy: 0.9086\n",
                        "Epoch 8/20\n",
                        "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2573 - accuracy: 0.9126 - val_loss: 0.2589 - val_accuracy: 0.9133\n",
                        "Epoch 9/20\n",
                        "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2519 - accuracy: 0.9134 - val_loss: 0.2562 - val_accuracy: 0.9141\n",
                        "Epoch 10/20\n",
                        "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2469 - accuracy: 0.9153 - val_loss: 0.2542 - val_accuracy: 0.9163\n",
                        "Epoch 11/20\n",
                        "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2423 - accuracy: 0.9176 - val_loss: 0.2496 - val_accuracy: 0.9153\n",
                        "Epoch 12/20\n",
                        "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2383 - accuracy: 0.9186 - val_loss: 0.2509 - val_accuracy: 0.9131\n",
                        "Epoch 13/20\n",
                        "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2351 - accuracy: 0.9200 - val_loss: 0.2446 - val_accuracy: 0.9155\n",
                        "Epoch 14/20\n",
                        "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2316 - accuracy: 0.9211 - val_loss: 0.2416 - val_accuracy: 0.9173\n",
                        "Epoch 15/20\n",
                        "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2288 - accuracy: 0.9213 - val_loss: 0.2448 - val_accuracy: 0.9190\n",
                        "Epoch 16/20\n",
                        "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2255 - accuracy: 0.9223 - val_loss: 0.2384 - val_accuracy: 0.9195\n",
                        "Epoch 17/20\n",
                        "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2231 - accuracy: 0.9233 - val_loss: 0.2410 - val_accuracy: 0.9170\n",
                        "Epoch 18/20\n",
                        "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2201 - accuracy: 0.9244 - val_loss: 0.2428 - val_accuracy: 0.9153\n",
                        "Epoch 19/20\n",
                        "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2178 - accuracy: 0.9253 - val_loss: 0.2330 - val_accuracy: 0.9200\n",
                        "Epoch 20/20\n",
                        "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2156 - accuracy: 0.9260 - val_loss: 0.2334 - val_accuracy: 0.9203\n"
                    ]
                }
            ],
            "source": [
                "history = model_A.fit(X_train_A,\n",
                "                      y_train_A,\n",
                "                      epochs=20,\n",
                "                      validation_data=(X_valid_A, y_valid_A))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 57,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_A.save(\"../../data-handson/my_model_A.h5\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 58,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_B = keras.models.Sequential()\n",
                "model_B.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
                "for n_hidden in (300, 100, 50, 50, 50):\n",
                "    model_B.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
                "model_B.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 59,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_B.compile(loss=\"binary_crossentropy\",\n",
                "                optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
                "                metrics=[\"accuracy\"])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 60,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/20\n",
                        "7/7 [==============================] - 0s 13ms/step - loss: 0.9573 - accuracy: 0.4650 - val_loss: 0.6314 - val_accuracy: 0.6004\n",
                        "Epoch 2/20\n",
                        "7/7 [==============================] - 0s 7ms/step - loss: 0.5692 - accuracy: 0.7450 - val_loss: 0.4784 - val_accuracy: 0.8529\n",
                        "Epoch 3/20\n",
                        "7/7 [==============================] - 0s 6ms/step - loss: 0.4503 - accuracy: 0.8650 - val_loss: 0.4102 - val_accuracy: 0.8945\n",
                        "Epoch 4/20\n",
                        "7/7 [==============================] - 0s 7ms/step - loss: 0.3879 - accuracy: 0.8950 - val_loss: 0.3647 - val_accuracy: 0.9178\n",
                        "Epoch 5/20\n",
                        "7/7 [==============================] - 0s 6ms/step - loss: 0.3435 - accuracy: 0.9250 - val_loss: 0.3300 - val_accuracy: 0.9320\n",
                        "Epoch 6/20\n",
                        "7/7 [==============================] - 0s 7ms/step - loss: 0.3081 - accuracy: 0.9300 - val_loss: 0.3019 - val_accuracy: 0.9402\n",
                        "Epoch 7/20\n",
                        "7/7 [==============================] - 0s 10ms/step - loss: 0.2800 - accuracy: 0.9350 - val_loss: 0.2804 - val_accuracy: 0.9422\n",
                        "Epoch 8/20\n",
                        "7/7 [==============================] - 0s 8ms/step - loss: 0.2564 - accuracy: 0.9450 - val_loss: 0.2606 - val_accuracy: 0.9473\n",
                        "Epoch 9/20\n",
                        "7/7 [==============================] - 0s 6ms/step - loss: 0.2362 - accuracy: 0.9550 - val_loss: 0.2428 - val_accuracy: 0.9523\n",
                        "Epoch 10/20\n",
                        "7/7 [==============================] - 0s 7ms/step - loss: 0.2188 - accuracy: 0.9600 - val_loss: 0.2281 - val_accuracy: 0.9544\n",
                        "Epoch 11/20\n",
                        "7/7 [==============================] - 0s 6ms/step - loss: 0.2036 - accuracy: 0.9700 - val_loss: 0.2150 - val_accuracy: 0.9584\n",
                        "Epoch 12/20\n",
                        "7/7 [==============================] - 0s 6ms/step - loss: 0.1898 - accuracy: 0.9700 - val_loss: 0.2036 - val_accuracy: 0.9584\n",
                        "Epoch 13/20\n",
                        "7/7 [==============================] - 0s 6ms/step - loss: 0.1773 - accuracy: 0.9750 - val_loss: 0.1931 - val_accuracy: 0.9615\n",
                        "Epoch 14/20\n",
                        "7/7 [==============================] - 0s 8ms/step - loss: 0.1668 - accuracy: 0.9800 - val_loss: 0.1838 - val_accuracy: 0.9635\n",
                        "Epoch 15/20\n",
                        "7/7 [==============================] - 0s 6ms/step - loss: 0.1570 - accuracy: 0.9900 - val_loss: 0.1746 - val_accuracy: 0.9686\n",
                        "Epoch 16/20\n",
                        "7/7 [==============================] - 0s 6ms/step - loss: 0.1481 - accuracy: 0.9900 - val_loss: 0.1674 - val_accuracy: 0.9686\n",
                        "Epoch 17/20\n",
                        "7/7 [==============================] - 0s 7ms/step - loss: 0.1406 - accuracy: 0.9900 - val_loss: 0.1604 - val_accuracy: 0.9706\n",
                        "Epoch 18/20\n",
                        "7/7 [==============================] - 0s 6ms/step - loss: 0.1334 - accuracy: 0.9900 - val_loss: 0.1539 - val_accuracy: 0.9706\n",
                        "Epoch 19/20\n",
                        "7/7 [==============================] - 0s 6ms/step - loss: 0.1268 - accuracy: 0.9900 - val_loss: 0.1482 - val_accuracy: 0.9716\n",
                        "Epoch 20/20\n",
                        "7/7 [==============================] - 0s 6ms/step - loss: 0.1208 - accuracy: 0.9900 - val_loss: 0.1431 - val_accuracy: 0.9716\n"
                    ]
                }
            ],
            "source": [
                "history = model_B.fit(X_train_B,\n",
                "                      y_train_B,\n",
                "                      epochs=20,\n",
                "                      validation_data=(X_valid_B, y_valid_B))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 61,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Model: \"sequential_7\"\n",
                        "_________________________________________________________________\n",
                        " Layer (type)                Output Shape              Param #   \n",
                        "=================================================================\n",
                        " flatten_7 (Flatten)         (None, 784)               0         \n",
                        "                                                                 \n",
                        " dense_224 (Dense)           (None, 300)               235500    \n",
                        "                                                                 \n",
                        " dense_225 (Dense)           (None, 100)               30100     \n",
                        "                                                                 \n",
                        " dense_226 (Dense)           (None, 50)                5050      \n",
                        "                                                                 \n",
                        " dense_227 (Dense)           (None, 50)                2550      \n",
                        "                                                                 \n",
                        " dense_228 (Dense)           (None, 50)                2550      \n",
                        "                                                                 \n",
                        " dense_229 (Dense)           (None, 1)                 51        \n",
                        "                                                                 \n",
                        "=================================================================\n",
                        "Total params: 275,801\n",
                        "Trainable params: 275,801\n",
                        "Non-trainable params: 0\n",
                        "_________________________________________________________________\n"
                    ]
                }
            ],
            "source": [
                "model_B.summary()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 87,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_A = keras.models.load_model(\"../../data-handson/my_model_A.h5\")\n",
                "model_B_on_A = keras.models.Sequential(model_A.layers[:-1])\n",
                "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Note that `model_B_on_A` and `model_A` actually share layers now, so when we train one, it will update both models. If we want to avoid that, we need to build `model_B_on_A` on top of a _clone_ of `model_A`:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 63,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_A_clone = keras.models.clone_model(model_A)\n",
                "model_A_clone.set_weights(model_A.get_weights())\n",
                "model_B_on_A = keras.models.Sequential(model_A_clone.layers[:-1])\n",
                "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 64,
            "metadata": {},
            "outputs": [],
            "source": [
                "for layer in model_B_on_A.layers[:-1]:\n",
                "    layer.trainable = False\n",
                "\n",
                "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
                "                     optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
                "                     metrics=[\"accuracy\"])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 65,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/4\n",
                        "7/7 [==============================] - 0s 14ms/step - loss: 0.2644 - accuracy: 0.9400 - val_loss: 0.2788 - val_accuracy: 0.9270\n",
                        "Epoch 2/4\n",
                        "7/7 [==============================] - 0s 6ms/step - loss: 0.2548 - accuracy: 0.9400 - val_loss: 0.2693 - val_accuracy: 0.9290\n",
                        "Epoch 3/4\n",
                        "7/7 [==============================] - 0s 6ms/step - loss: 0.2455 - accuracy: 0.9400 - val_loss: 0.2606 - val_accuracy: 0.9341\n",
                        "Epoch 4/4\n",
                        "7/7 [==============================] - 0s 5ms/step - loss: 0.2370 - accuracy: 0.9400 - val_loss: 0.2525 - val_accuracy: 0.9381\n",
                        "Epoch 1/16\n",
                        "7/7 [==============================] - 0s 14ms/step - loss: 0.2120 - accuracy: 0.9450 - val_loss: 0.2042 - val_accuracy: 0.9635\n",
                        "Epoch 2/16\n",
                        "7/7 [==============================] - 0s 6ms/step - loss: 0.1695 - accuracy: 0.9550 - val_loss: 0.1718 - val_accuracy: 0.9716\n",
                        "Epoch 3/16\n",
                        "7/7 [==============================] - 0s 6ms/step - loss: 0.1405 - accuracy: 0.9700 - val_loss: 0.1492 - val_accuracy: 0.9807\n",
                        "Epoch 4/16\n",
                        "7/7 [==============================] - 0s 6ms/step - loss: 0.1196 - accuracy: 0.9800 - val_loss: 0.1326 - val_accuracy: 0.9828\n",
                        "Epoch 5/16\n",
                        "7/7 [==============================] - 0s 6ms/step - loss: 0.1045 - accuracy: 0.9900 - val_loss: 0.1201 - val_accuracy: 0.9848\n",
                        "Epoch 6/16\n",
                        "7/7 [==============================] - 0s 6ms/step - loss: 0.0928 - accuracy: 0.9950 - val_loss: 0.1103 - val_accuracy: 0.9858\n",
                        "Epoch 7/16\n",
                        "7/7 [==============================] - 0s 6ms/step - loss: 0.0836 - accuracy: 0.9950 - val_loss: 0.1021 - val_accuracy: 0.9858\n",
                        "Epoch 8/16\n",
                        "7/7 [==============================] - 0s 6ms/step - loss: 0.0762 - accuracy: 0.9950 - val_loss: 0.0954 - val_accuracy: 0.9878\n",
                        "Epoch 9/16\n",
                        "7/7 [==============================] - 0s 6ms/step - loss: 0.0698 - accuracy: 0.9950 - val_loss: 0.0893 - val_accuracy: 0.9868\n",
                        "Epoch 10/16\n",
                        "7/7 [==============================] - 0s 6ms/step - loss: 0.0641 - accuracy: 0.9950 - val_loss: 0.0845 - val_accuracy: 0.9888\n",
                        "Epoch 11/16\n",
                        "7/7 [==============================] - 0s 6ms/step - loss: 0.0596 - accuracy: 1.0000 - val_loss: 0.0801 - val_accuracy: 0.9888\n",
                        "Epoch 12/16\n",
                        "7/7 [==============================] - 0s 7ms/step - loss: 0.0554 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 0.9888\n",
                        "Epoch 13/16\n",
                        "7/7 [==============================] - 0s 6ms/step - loss: 0.0517 - accuracy: 1.0000 - val_loss: 0.0729 - val_accuracy: 0.9888\n",
                        "Epoch 14/16\n",
                        "7/7 [==============================] - 0s 6ms/step - loss: 0.0485 - accuracy: 1.0000 - val_loss: 0.0701 - val_accuracy: 0.9878\n",
                        "Epoch 15/16\n",
                        "7/7 [==============================] - 0s 6ms/step - loss: 0.0459 - accuracy: 1.0000 - val_loss: 0.0676 - val_accuracy: 0.9878\n",
                        "Epoch 16/16\n",
                        "7/7 [==============================] - 0s 6ms/step - loss: 0.0435 - accuracy: 1.0000 - val_loss: 0.0653 - val_accuracy: 0.9878\n"
                    ]
                }
            ],
            "source": [
                "history = model_B_on_A.fit(X_train_B,\n",
                "                           y_train_B,\n",
                "                           epochs=4,\n",
                "                           validation_data=(X_valid_B, y_valid_B))\n",
                "\n",
                "for layer in model_B_on_A.layers[:-1]:\n",
                "    layer.trainable = True\n",
                "\n",
                "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
                "                     optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
                "                     metrics=[\"accuracy\"])\n",
                "history = model_B_on_A.fit(X_train_B,\n",
                "                           y_train_B,\n",
                "                           epochs=16,\n",
                "                           validation_data=(X_valid_B, y_valid_B))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "So, what's the final verdict?\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 66,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "63/63 [==============================] - 0s 728us/step - loss: 0.1408 - accuracy: 0.9705\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "[0.1408407986164093, 0.9704999923706055]"
                        ]
                    },
                    "execution_count": 66,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "model_B.evaluate(X_test_B, y_test_B)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 67,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "63/63 [==============================] - 0s 721us/step - loss: 0.0563 - accuracy: 0.9940\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "[0.0563034787774086, 0.9940000176429749]"
                        ]
                    },
                    "execution_count": 67,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "model_B_on_A.evaluate(X_test_B, y_test_B)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Great! We got quite a bit of transfer: the error rate dropped by a factor of 4.9!\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 68,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "4.916666666666718"
                        ]
                    },
                    "execution_count": 68,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "(100 - 97.05) / (100 - 99.40)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Faster Optimizers\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Momentum optimization\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 69,
            "metadata": {},
            "outputs": [],
            "source": [
                "optimizer = keras.optimizers.SGD(learning_rate=0.001, momentum=0.9)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Nesterov Accelerated Gradient\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 70,
            "metadata": {},
            "outputs": [],
            "source": [
                "optimizer = keras.optimizers.SGD(learning_rate=0.001,\n",
                "                                 momentum=0.9,\n",
                "                                 nesterov=True)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## AdaGrad\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 71,
            "metadata": {},
            "outputs": [],
            "source": [
                "optimizer = keras.optimizers.Adagrad(learning_rate=0.001)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## RMSProp\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 72,
            "metadata": {},
            "outputs": [],
            "source": [
                "optimizer = keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Adam Optimization\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 73,
            "metadata": {},
            "outputs": [],
            "source": [
                "optimizer = keras.optimizers.Adam(learning_rate=0.001,\n",
                "                                  beta_1=0.9,\n",
                "                                  beta_2=0.999)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Adamax Optimization\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 74,
            "metadata": {},
            "outputs": [],
            "source": [
                "optimizer = keras.optimizers.Adamax(learning_rate=0.001,\n",
                "                                    beta_1=0.9,\n",
                "                                    beta_2=0.999)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Nadam Optimization\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 75,
            "metadata": {},
            "outputs": [],
            "source": [
                "optimizer = keras.optimizers.Nadam(learning_rate=0.001,\n",
                "                                   beta_1=0.9,\n",
                "                                   beta_2=0.999)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Learning Rate Scheduling\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Power Scheduling\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "`lr = lr0 / (1 + steps / s)**c`\n",
                "\n",
                "- Keras uses `c=1` and `s = 1 / decay`\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 76,
            "metadata": {},
            "outputs": [],
            "source": [
                "optimizer = keras.optimizers.SGD(learning_rate=0.01, decay=1e-4)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 77,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = keras.models.Sequential([\n",
                "    keras.layers.Flatten(input_shape=[28, 28]),\n",
                "    keras.layers.Dense(300,\n",
                "                       activation=\"selu\",\n",
                "                       kernel_initializer=\"lecun_normal\"),\n",
                "    keras.layers.Dense(100,\n",
                "                       activation=\"selu\",\n",
                "                       kernel_initializer=\"lecun_normal\"),\n",
                "    keras.layers.Dense(10, activation=\"softmax\")\n",
                "])\n",
                "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
                "              optimizer=optimizer,\n",
                "              metrics=[\"accuracy\"])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 78,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4898 - accuracy: 0.8266 - val_loss: 0.4066 - val_accuracy: 0.8598\n",
                        "Epoch 2/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3793 - accuracy: 0.8654 - val_loss: 0.3730 - val_accuracy: 0.8706\n",
                        "Epoch 3/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3468 - accuracy: 0.8777 - val_loss: 0.3744 - val_accuracy: 0.8716\n",
                        "Epoch 4/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3259 - accuracy: 0.8847 - val_loss: 0.3508 - val_accuracy: 0.8790\n",
                        "Epoch 5/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3108 - accuracy: 0.8895 - val_loss: 0.3449 - val_accuracy: 0.8782\n",
                        "Epoch 6/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2973 - accuracy: 0.8939 - val_loss: 0.3417 - val_accuracy: 0.8850\n",
                        "Epoch 7/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2871 - accuracy: 0.8982 - val_loss: 0.3379 - val_accuracy: 0.8828\n",
                        "Epoch 8/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2780 - accuracy: 0.9013 - val_loss: 0.3421 - val_accuracy: 0.8790\n",
                        "Epoch 9/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2698 - accuracy: 0.9030 - val_loss: 0.3290 - val_accuracy: 0.8862\n",
                        "Epoch 10/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2624 - accuracy: 0.9061 - val_loss: 0.3282 - val_accuracy: 0.8860\n",
                        "Epoch 11/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2565 - accuracy: 0.9091 - val_loss: 0.3264 - val_accuracy: 0.8880\n",
                        "Epoch 12/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2504 - accuracy: 0.9112 - val_loss: 0.3336 - val_accuracy: 0.8804\n",
                        "Epoch 13/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2448 - accuracy: 0.9136 - val_loss: 0.3246 - val_accuracy: 0.8898\n",
                        "Epoch 14/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2407 - accuracy: 0.9147 - val_loss: 0.3284 - val_accuracy: 0.8846\n",
                        "Epoch 15/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2354 - accuracy: 0.9167 - val_loss: 0.3224 - val_accuracy: 0.8884\n",
                        "Epoch 16/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2315 - accuracy: 0.9186 - val_loss: 0.3204 - val_accuracy: 0.8886\n",
                        "Epoch 17/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2276 - accuracy: 0.9189 - val_loss: 0.3241 - val_accuracy: 0.8886\n",
                        "Epoch 18/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2235 - accuracy: 0.9213 - val_loss: 0.3187 - val_accuracy: 0.8920\n",
                        "Epoch 19/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2202 - accuracy: 0.9227 - val_loss: 0.3226 - val_accuracy: 0.8892\n",
                        "Epoch 20/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2169 - accuracy: 0.9238 - val_loss: 0.3201 - val_accuracy: 0.8904\n",
                        "Epoch 21/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2132 - accuracy: 0.9256 - val_loss: 0.3201 - val_accuracy: 0.8890\n",
                        "Epoch 22/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2107 - accuracy: 0.9267 - val_loss: 0.3179 - val_accuracy: 0.8900\n",
                        "Epoch 23/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2078 - accuracy: 0.9272 - val_loss: 0.3202 - val_accuracy: 0.8906\n",
                        "Epoch 24/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2050 - accuracy: 0.9291 - val_loss: 0.3201 - val_accuracy: 0.8902\n",
                        "Epoch 25/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2027 - accuracy: 0.9293 - val_loss: 0.3197 - val_accuracy: 0.8902\n"
                    ]
                }
            ],
            "source": [
                "n_epochs = 25\n",
                "history = model.fit(X_train_scaled,\n",
                "                    y_train,\n",
                "                    epochs=n_epochs,\n",
                "                    validation_data=(X_valid_scaled, y_valid))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 79,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 432x288 with 1 Axes>"
                        ]
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": [
                "import math\n",
                "\n",
                "learning_rate = 0.01\n",
                "decay = 1e-4\n",
                "batch_size = 32\n",
                "n_steps_per_epoch = math.ceil(len(X_train) / batch_size)\n",
                "epochs = np.arange(n_epochs)\n",
                "lrs = learning_rate / (1 + decay * epochs * n_steps_per_epoch)\n",
                "\n",
                "plt.plot(epochs, lrs, \"o-\")\n",
                "plt.axis([0, n_epochs - 1, 0, 0.01])\n",
                "plt.xlabel(\"Epoch\")\n",
                "plt.ylabel(\"Learning Rate\")\n",
                "plt.title(\"Power Scheduling\", fontsize=14)\n",
                "plt.grid(True)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exponential Scheduling\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "`lr = lr0 * 0.1**(epoch / s)`\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 80,
            "metadata": {},
            "outputs": [],
            "source": [
                "def exponential_decay_fn(epoch):\n",
                "    return 0.01 * 0.1**(epoch / 20)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 81,
            "metadata": {},
            "outputs": [],
            "source": [
                "def exponential_decay(lr0, s):\n",
                "\n",
                "    def exponential_decay_fn(epoch):\n",
                "        return lr0 * 0.1**(epoch / s)\n",
                "\n",
                "    return exponential_decay_fn\n",
                "\n",
                "\n",
                "exponential_decay_fn = exponential_decay(lr0=0.01, s=20)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 82,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = keras.models.Sequential([\n",
                "    keras.layers.Flatten(input_shape=[28, 28]),\n",
                "    keras.layers.Dense(300,\n",
                "                       activation=\"selu\",\n",
                "                       kernel_initializer=\"lecun_normal\"),\n",
                "    keras.layers.Dense(100,\n",
                "                       activation=\"selu\",\n",
                "                       kernel_initializer=\"lecun_normal\"),\n",
                "    keras.layers.Dense(10, activation=\"softmax\")\n",
                "])\n",
                "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
                "              optimizer=\"nadam\",\n",
                "              metrics=[\"accuracy\"])\n",
                "n_epochs = 25"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 83,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.8694 - accuracy: 0.7500 - val_loss: 0.7946 - val_accuracy: 0.7696 - lr: 0.0100\n",
                        "Epoch 2/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.7062 - accuracy: 0.7870 - val_loss: 0.5598 - val_accuracy: 0.8376 - lr: 0.0089\n",
                        "Epoch 3/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6169 - accuracy: 0.8105 - val_loss: 0.7057 - val_accuracy: 0.7634 - lr: 0.0079\n",
                        "Epoch 4/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5765 - accuracy: 0.8278 - val_loss: 0.5878 - val_accuracy: 0.8268 - lr: 0.0071\n",
                        "Epoch 5/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4933 - accuracy: 0.8456 - val_loss: 0.4915 - val_accuracy: 0.8568 - lr: 0.0063\n",
                        "Epoch 6/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4343 - accuracy: 0.8608 - val_loss: 0.4700 - val_accuracy: 0.8598 - lr: 0.0056\n",
                        "Epoch 7/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4058 - accuracy: 0.8699 - val_loss: 0.5097 - val_accuracy: 0.8508 - lr: 0.0050\n",
                        "Epoch 8/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3785 - accuracy: 0.8788 - val_loss: 0.5295 - val_accuracy: 0.8338 - lr: 0.0045\n",
                        "Epoch 9/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3484 - accuracy: 0.8853 - val_loss: 0.5490 - val_accuracy: 0.8716 - lr: 0.0040\n",
                        "Epoch 10/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3258 - accuracy: 0.8916 - val_loss: 0.4592 - val_accuracy: 0.8700 - lr: 0.0035\n",
                        "Epoch 11/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3015 - accuracy: 0.8977 - val_loss: 0.5062 - val_accuracy: 0.8654 - lr: 0.0032\n",
                        "Epoch 12/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2781 - accuracy: 0.9063 - val_loss: 0.4950 - val_accuracy: 0.8750 - lr: 0.0028\n",
                        "Epoch 13/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2626 - accuracy: 0.9107 - val_loss: 0.5087 - val_accuracy: 0.8824 - lr: 0.0025\n",
                        "Epoch 14/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2397 - accuracy: 0.9167 - val_loss: 0.4896 - val_accuracy: 0.8696 - lr: 0.0022\n",
                        "Epoch 15/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2233 - accuracy: 0.9234 - val_loss: 0.4539 - val_accuracy: 0.8844 - lr: 0.0020\n",
                        "Epoch 16/25\n",
                        "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2068 - accuracy: 0.9292 - val_loss: 0.4851 - val_accuracy: 0.8856 - lr: 0.0018\n",
                        "Epoch 17/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1903 - accuracy: 0.9338 - val_loss: 0.4970 - val_accuracy: 0.8850 - lr: 0.0016\n",
                        "Epoch 18/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1789 - accuracy: 0.9389 - val_loss: 0.5263 - val_accuracy: 0.8864 - lr: 0.0014\n",
                        "Epoch 19/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1667 - accuracy: 0.9436 - val_loss: 0.5536 - val_accuracy: 0.8884 - lr: 0.0013\n",
                        "Epoch 20/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1555 - accuracy: 0.9467 - val_loss: 0.5226 - val_accuracy: 0.8870 - lr: 0.0011\n",
                        "Epoch 21/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1444 - accuracy: 0.9507 - val_loss: 0.6078 - val_accuracy: 0.8852 - lr: 0.0010\n",
                        "Epoch 22/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1356 - accuracy: 0.9548 - val_loss: 0.5943 - val_accuracy: 0.8852 - lr: 8.9125e-04\n",
                        "Epoch 23/25\n",
                        "1719/1719 [==============================] - 4s 3ms/step - loss: 0.1271 - accuracy: 0.9583 - val_loss: 0.6243 - val_accuracy: 0.8848 - lr: 7.9433e-04\n",
                        "Epoch 24/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1190 - accuracy: 0.9609 - val_loss: 0.6511 - val_accuracy: 0.8888 - lr: 7.0795e-04\n",
                        "Epoch 25/25\n",
                        "1719/1719 [==============================] - 4s 3ms/step - loss: 0.1129 - accuracy: 0.9633 - val_loss: 0.6630 - val_accuracy: 0.8884 - lr: 6.3096e-04\n"
                    ]
                }
            ],
            "source": [
                "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
                "history = model.fit(X_train_scaled,\n",
                "                    y_train,\n",
                "                    epochs=n_epochs,\n",
                "                    validation_data=(X_valid_scaled, y_valid),\n",
                "                    callbacks=[lr_scheduler])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 84,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 432x288 with 1 Axes>"
                        ]
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": [
                "plt.plot(history.epoch, history.history[\"lr\"], \"o-\")\n",
                "plt.axis([0, n_epochs - 1, 0, 0.011])\n",
                "plt.xlabel(\"Epoch\")\n",
                "plt.ylabel(\"Learning Rate\")\n",
                "plt.title(\"Exponential Scheduling\", fontsize=14)\n",
                "plt.grid(True)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The schedule function can take the current learning rate as a second argument:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 85,
            "metadata": {},
            "outputs": [],
            "source": [
                "def exponential_decay_fn(epoch, lr):\n",
                "    return lr * 0.1**(1 / 20)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "If you want to update the learning rate at each iteration rather than at each epoch, you must write your own callback class:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 88,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/25\n",
                        "1719/1719 [==============================] - 5s 3ms/step - loss: 0.7735 - accuracy: 0.7703 - val_loss: 0.7836 - val_accuracy: 0.7650 - lr: 0.0089\n",
                        "Epoch 2/25\n",
                        "1719/1719 [==============================] - 6s 3ms/step - loss: 0.6543 - accuracy: 0.8005 - val_loss: 0.5268 - val_accuracy: 0.8298 - lr: 0.0079\n",
                        "Epoch 3/25\n",
                        "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5709 - accuracy: 0.8263 - val_loss: 0.7578 - val_accuracy: 0.7424 - lr: 0.0071\n",
                        "Epoch 4/25\n",
                        "1719/1719 [==============================] - 4s 3ms/step - loss: 0.5168 - accuracy: 0.8389 - val_loss: 0.5710 - val_accuracy: 0.8452 - lr: 0.0063\n",
                        "Epoch 5/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4606 - accuracy: 0.8549 - val_loss: 0.4416 - val_accuracy: 0.8588 - lr: 0.0056\n",
                        "Epoch 6/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4211 - accuracy: 0.8650 - val_loss: 0.4687 - val_accuracy: 0.8594 - lr: 0.0050\n",
                        "Epoch 7/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4103 - accuracy: 0.8710 - val_loss: 0.4625 - val_accuracy: 0.8612 - lr: 0.0045\n",
                        "Epoch 8/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3593 - accuracy: 0.8798 - val_loss: 0.4646 - val_accuracy: 0.8534 - lr: 0.0040\n",
                        "Epoch 9/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3353 - accuracy: 0.8892 - val_loss: 0.4827 - val_accuracy: 0.8572 - lr: 0.0035\n",
                        "Epoch 10/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3157 - accuracy: 0.8946 - val_loss: 0.4251 - val_accuracy: 0.8854 - lr: 0.0032\n",
                        "Epoch 11/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2884 - accuracy: 0.9016 - val_loss: 0.4509 - val_accuracy: 0.8816 - lr: 0.0028\n",
                        "Epoch 12/25\n",
                        "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2664 - accuracy: 0.9080 - val_loss: 0.4533 - val_accuracy: 0.8786 - lr: 0.0025\n",
                        "Epoch 13/25\n",
                        "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2511 - accuracy: 0.9133 - val_loss: 0.4890 - val_accuracy: 0.8814 - lr: 0.0022\n",
                        "Epoch 14/25\n",
                        "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2305 - accuracy: 0.9206 - val_loss: 0.4616 - val_accuracy: 0.8844 - lr: 0.0020\n",
                        "Epoch 15/25\n",
                        "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2156 - accuracy: 0.9253 - val_loss: 0.4573 - val_accuracy: 0.8826 - lr: 0.0018\n",
                        "Epoch 16/25\n",
                        "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1980 - accuracy: 0.9325 - val_loss: 0.4688 - val_accuracy: 0.8872 - lr: 0.0016\n",
                        "Epoch 17/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1834 - accuracy: 0.9361 - val_loss: 0.4902 - val_accuracy: 0.8860 - lr: 0.0014\n",
                        "Epoch 18/25\n",
                        "1719/1719 [==============================] - 6s 4ms/step - loss: 0.1708 - accuracy: 0.9410 - val_loss: 0.4934 - val_accuracy: 0.8868 - lr: 0.0013\n",
                        "Epoch 19/25\n",
                        "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1590 - accuracy: 0.9460 - val_loss: 0.5106 - val_accuracy: 0.8918 - lr: 0.0011\n",
                        "Epoch 20/25\n",
                        "1719/1719 [==============================] - 6s 3ms/step - loss: 0.1503 - accuracy: 0.9499 - val_loss: 0.5142 - val_accuracy: 0.8894 - lr: 9.9967e-04\n",
                        "Epoch 21/25\n",
                        "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1367 - accuracy: 0.9538 - val_loss: 0.5779 - val_accuracy: 0.8868 - lr: 8.9094e-04\n",
                        "Epoch 22/25\n",
                        "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1296 - accuracy: 0.9558 - val_loss: 0.5952 - val_accuracy: 0.8890 - lr: 7.9404e-04\n",
                        "Epoch 23/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1189 - accuracy: 0.9605 - val_loss: 0.6082 - val_accuracy: 0.8864 - lr: 7.0767e-04\n",
                        "Epoch 24/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1118 - accuracy: 0.9638 - val_loss: 0.6440 - val_accuracy: 0.8872 - lr: 6.3071e-04\n",
                        "Epoch 25/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1056 - accuracy: 0.9657 - val_loss: 0.6508 - val_accuracy: 0.8884 - lr: 5.6211e-04\n"
                    ]
                }
            ],
            "source": [
                "K = keras.backend\n",
                "\n",
                "\n",
                "class ExponentialDecay(keras.callbacks.Callback):\n",
                "\n",
                "    def __init__(self, s=40000):\n",
                "        super().__init__()\n",
                "        self.s = s\n",
                "\n",
                "    def on_batch_begin(self, batch, logs=None):\n",
                "        # Note: the `batch` argument is reset at each epoch\n",
                "        lr = K.get_value(self.model.optimizer.learning_rate)\n",
                "        K.set_value(self.model.optimizer.learning_rate, lr * 0.1**(1 / self.s))\n",
                "\n",
                "    def on_epoch_end(self, epoch, logs=None):\n",
                "        logs = logs or {}\n",
                "        logs['lr'] = K.get_value(self.model.optimizer.learning_rate)\n",
                "\n",
                "\n",
                "model = keras.models.Sequential([\n",
                "    keras.layers.Flatten(input_shape=[28, 28]),\n",
                "    keras.layers.Dense(300,\n",
                "                       activation=\"selu\",\n",
                "                       kernel_initializer=\"lecun_normal\"),\n",
                "    keras.layers.Dense(100,\n",
                "                       activation=\"selu\",\n",
                "                       kernel_initializer=\"lecun_normal\"),\n",
                "    keras.layers.Dense(10, activation=\"softmax\")\n",
                "])\n",
                "lr0 = 0.01\n",
                "optimizer = keras.optimizers.Nadam(learning_rate=lr0)\n",
                "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
                "              optimizer=optimizer,\n",
                "              metrics=[\"accuracy\"])\n",
                "n_epochs = 25\n",
                "\n",
                "s = 20 * len(X_train) // 32  # number of steps in 20 epochs (batch size = 32)\n",
                "exp_decay = ExponentialDecay(s)\n",
                "history = model.fit(X_train_scaled,\n",
                "                    y_train,\n",
                "                    epochs=n_epochs,\n",
                "                    validation_data=(X_valid_scaled, y_valid),\n",
                "                    callbacks=[exp_decay])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 89,
            "metadata": {},
            "outputs": [],
            "source": [
                "n_steps = n_epochs * len(X_train) // 32\n",
                "steps = np.arange(n_steps)\n",
                "lrs = lr0 * 0.1**(steps / s)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 90,
            "metadata": {
                "scrolled": true
            },
            "outputs": [
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 432x288 with 1 Axes>"
                        ]
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": [
                "plt.plot(steps, lrs, \"-\", linewidth=2)\n",
                "plt.axis([0, n_steps - 1, 0, lr0 * 1.1])\n",
                "plt.xlabel(\"Batch\")\n",
                "plt.ylabel(\"Learning Rate\")\n",
                "plt.title(\"Exponential Scheduling (per batch)\", fontsize=14)\n",
                "plt.grid(True)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Piecewise Constant Scheduling\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 91,
            "metadata": {},
            "outputs": [],
            "source": [
                "def piecewise_constant_fn(epoch):\n",
                "    if epoch < 5:\n",
                "        return 0.01\n",
                "    elif epoch < 15:\n",
                "        return 0.005\n",
                "    else:\n",
                "        return 0.001"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 92,
            "metadata": {},
            "outputs": [],
            "source": [
                "def piecewise_constant(boundaries, values):\n",
                "    boundaries = np.array([0] + boundaries)\n",
                "    values = np.array(values)\n",
                "\n",
                "    def piecewise_constant_fn(epoch):\n",
                "        return values[np.argmax(boundaries > epoch) - 1]\n",
                "\n",
                "    return piecewise_constant_fn\n",
                "\n",
                "\n",
                "piecewise_constant_fn = piecewise_constant([5, 15], [0.01, 0.005, 0.001])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 93,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.9283 - accuracy: 0.7331 - val_loss: 1.4121 - val_accuracy: 0.6498 - lr: 0.0100\n",
                        "Epoch 2/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.9669 - accuracy: 0.6849 - val_loss: 1.2677 - val_accuracy: 0.6518 - lr: 0.0100\n",
                        "Epoch 3/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 1.2712 - accuracy: 0.6010 - val_loss: 1.7695 - val_accuracy: 0.4998 - lr: 0.0100\n",
                        "Epoch 4/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 1.1708 - accuracy: 0.6014 - val_loss: 1.4002 - val_accuracy: 0.5300 - lr: 0.0100\n",
                        "Epoch 5/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 1.0151 - accuracy: 0.6181 - val_loss: 1.0774 - val_accuracy: 0.5994 - lr: 0.0100\n",
                        "Epoch 6/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.8327 - accuracy: 0.6631 - val_loss: 0.8164 - val_accuracy: 0.6884 - lr: 0.0050\n",
                        "Epoch 7/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.8117 - accuracy: 0.6746 - val_loss: 0.8706 - val_accuracy: 0.6702 - lr: 0.0050\n",
                        "Epoch 8/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.7200 - accuracy: 0.7344 - val_loss: 0.7971 - val_accuracy: 0.7572 - lr: 0.0050\n",
                        "Epoch 9/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6775 - accuracy: 0.7628 - val_loss: 0.7060 - val_accuracy: 0.7772 - lr: 0.0050\n",
                        "Epoch 10/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6060 - accuracy: 0.7950 - val_loss: 0.6812 - val_accuracy: 0.8394 - lr: 0.0050\n",
                        "Epoch 11/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5242 - accuracy: 0.8488 - val_loss: 0.6289 - val_accuracy: 0.8454 - lr: 0.0050\n",
                        "Epoch 12/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5123 - accuracy: 0.8530 - val_loss: 0.6204 - val_accuracy: 0.8386 - lr: 0.0050\n",
                        "Epoch 13/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4837 - accuracy: 0.8584 - val_loss: 0.6477 - val_accuracy: 0.8530 - lr: 0.0050\n",
                        "Epoch 14/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4812 - accuracy: 0.8619 - val_loss: 0.5980 - val_accuracy: 0.8578 - lr: 0.0050\n",
                        "Epoch 15/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4842 - accuracy: 0.8615 - val_loss: 0.6496 - val_accuracy: 0.8554 - lr: 0.0050\n",
                        "Epoch 16/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3347 - accuracy: 0.8953 - val_loss: 0.5381 - val_accuracy: 0.8688 - lr: 0.0010\n",
                        "Epoch 17/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3093 - accuracy: 0.9025 - val_loss: 0.5626 - val_accuracy: 0.8678 - lr: 0.0010\n",
                        "Epoch 18/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2989 - accuracy: 0.9053 - val_loss: 0.5438 - val_accuracy: 0.8752 - lr: 0.0010\n",
                        "Epoch 19/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2850 - accuracy: 0.9099 - val_loss: 0.5420 - val_accuracy: 0.8734 - lr: 0.0010\n",
                        "Epoch 20/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2769 - accuracy: 0.9134 - val_loss: 0.5520 - val_accuracy: 0.8732 - lr: 0.0010\n",
                        "Epoch 21/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2650 - accuracy: 0.9153 - val_loss: 0.5633 - val_accuracy: 0.8756 - lr: 0.0010\n",
                        "Epoch 22/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2557 - accuracy: 0.9185 - val_loss: 0.5834 - val_accuracy: 0.8766 - lr: 0.0010\n",
                        "Epoch 23/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2473 - accuracy: 0.9210 - val_loss: 0.6078 - val_accuracy: 0.8736 - lr: 0.0010\n",
                        "Epoch 24/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2425 - accuracy: 0.9225 - val_loss: 0.6128 - val_accuracy: 0.8790 - lr: 0.0010\n",
                        "Epoch 25/25\n",
                        "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2364 - accuracy: 0.9252 - val_loss: 0.6309 - val_accuracy: 0.8788 - lr: 0.0010\n"
                    ]
                }
            ],
            "source": [
                "lr_scheduler = keras.callbacks.LearningRateScheduler(piecewise_constant_fn)\n",
                "\n",
                "model = keras.models.Sequential([\n",
                "    keras.layers.Flatten(input_shape=[28, 28]),\n",
                "    keras.layers.Dense(300,\n",
                "                       activation=\"selu\",\n",
                "                       kernel_initializer=\"lecun_normal\"),\n",
                "    keras.layers.Dense(100,\n",
                "                       activation=\"selu\",\n",
                "                       kernel_initializer=\"lecun_normal\"),\n",
                "    keras.layers.Dense(10, activation=\"softmax\")\n",
                "])\n",
                "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
                "              optimizer=\"nadam\",\n",
                "              metrics=[\"accuracy\"])\n",
                "n_epochs = 25\n",
                "history = model.fit(X_train_scaled,\n",
                "                    y_train,\n",
                "                    epochs=n_epochs,\n",
                "                    validation_data=(X_valid_scaled, y_valid),\n",
                "                    callbacks=[lr_scheduler])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 94,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 432x288 with 1 Axes>"
                        ]
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": [
                "plt.plot(history.epoch,\n",
                "         [piecewise_constant_fn(epoch) for epoch in history.epoch], \"o-\")\n",
                "plt.axis([0, n_epochs - 1, 0, 0.011])\n",
                "plt.xlabel(\"Epoch\")\n",
                "plt.ylabel(\"Learning Rate\")\n",
                "plt.title(\"Piecewise Constant Scheduling\", fontsize=14)\n",
                "plt.grid(True)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Performance Scheduling\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 95,
            "metadata": {},
            "outputs": [],
            "source": [
                "tf.random.set_seed(42)\n",
                "np.random.seed(42)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 96,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.5888 - accuracy: 0.8078 - val_loss: 0.4850 - val_accuracy: 0.8522 - lr: 0.0200\n",
                        "Epoch 2/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4965 - accuracy: 0.8409 - val_loss: 0.6062 - val_accuracy: 0.8410 - lr: 0.0200\n",
                        "Epoch 3/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.5055 - accuracy: 0.8422 - val_loss: 0.4817 - val_accuracy: 0.8610 - lr: 0.0200\n",
                        "Epoch 4/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.5063 - accuracy: 0.8489 - val_loss: 0.5140 - val_accuracy: 0.8514 - lr: 0.0200\n",
                        "Epoch 5/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.5376 - accuracy: 0.8475 - val_loss: 0.5676 - val_accuracy: 0.8412 - lr: 0.0200\n",
                        "Epoch 6/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.5226 - accuracy: 0.8513 - val_loss: 0.5713 - val_accuracy: 0.8474 - lr: 0.0200\n",
                        "Epoch 7/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.5354 - accuracy: 0.8529 - val_loss: 0.6554 - val_accuracy: 0.8242 - lr: 0.0200\n",
                        "Epoch 8/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.5259 - accuracy: 0.8561 - val_loss: 0.6540 - val_accuracy: 0.8172 - lr: 0.0200\n",
                        "Epoch 9/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2948 - accuracy: 0.8972 - val_loss: 0.4188 - val_accuracy: 0.8782 - lr: 0.0100\n",
                        "Epoch 10/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2507 - accuracy: 0.9110 - val_loss: 0.4170 - val_accuracy: 0.8860 - lr: 0.0100\n",
                        "Epoch 11/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2251 - accuracy: 0.9167 - val_loss: 0.4230 - val_accuracy: 0.8860 - lr: 0.0100\n",
                        "Epoch 12/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2154 - accuracy: 0.9209 - val_loss: 0.4306 - val_accuracy: 0.8752 - lr: 0.0100\n",
                        "Epoch 13/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2029 - accuracy: 0.9248 - val_loss: 0.4998 - val_accuracy: 0.8806 - lr: 0.0100\n",
                        "Epoch 14/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.1878 - accuracy: 0.9297 - val_loss: 0.4745 - val_accuracy: 0.8722 - lr: 0.0100\n",
                        "Epoch 15/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.1816 - accuracy: 0.9323 - val_loss: 0.4586 - val_accuracy: 0.8812 - lr: 0.0100\n",
                        "Epoch 16/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.1258 - accuracy: 0.9514 - val_loss: 0.4485 - val_accuracy: 0.8934 - lr: 0.0050\n",
                        "Epoch 17/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.1123 - accuracy: 0.9565 - val_loss: 0.4572 - val_accuracy: 0.8912 - lr: 0.0050\n",
                        "Epoch 18/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.1030 - accuracy: 0.9591 - val_loss: 0.4971 - val_accuracy: 0.8880 - lr: 0.0050\n",
                        "Epoch 19/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.0978 - accuracy: 0.9621 - val_loss: 0.5115 - val_accuracy: 0.8904 - lr: 0.0050\n",
                        "Epoch 20/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.0920 - accuracy: 0.9640 - val_loss: 0.5072 - val_accuracy: 0.8888 - lr: 0.0050\n",
                        "Epoch 21/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.0712 - accuracy: 0.9738 - val_loss: 0.5290 - val_accuracy: 0.8942 - lr: 0.0025\n",
                        "Epoch 22/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.0660 - accuracy: 0.9755 - val_loss: 0.5356 - val_accuracy: 0.8912 - lr: 0.0025\n",
                        "Epoch 23/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.0622 - accuracy: 0.9769 - val_loss: 0.5569 - val_accuracy: 0.8896 - lr: 0.0025\n",
                        "Epoch 24/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.0590 - accuracy: 0.9783 - val_loss: 0.5564 - val_accuracy: 0.8898 - lr: 0.0025\n",
                        "Epoch 25/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.0564 - accuracy: 0.9796 - val_loss: 0.5823 - val_accuracy: 0.8930 - lr: 0.0025\n"
                    ]
                }
            ],
            "source": [
                "lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\n",
                "\n",
                "model = keras.models.Sequential([\n",
                "    keras.layers.Flatten(input_shape=[28, 28]),\n",
                "    keras.layers.Dense(300,\n",
                "                       activation=\"selu\",\n",
                "                       kernel_initializer=\"lecun_normal\"),\n",
                "    keras.layers.Dense(100,\n",
                "                       activation=\"selu\",\n",
                "                       kernel_initializer=\"lecun_normal\"),\n",
                "    keras.layers.Dense(10, activation=\"softmax\")\n",
                "])\n",
                "optimizer = keras.optimizers.SGD(learning_rate=0.02, momentum=0.9)\n",
                "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
                "              optimizer=optimizer,\n",
                "              metrics=[\"accuracy\"])\n",
                "n_epochs = 25\n",
                "history = model.fit(X_train_scaled,\n",
                "                    y_train,\n",
                "                    epochs=n_epochs,\n",
                "                    validation_data=(X_valid_scaled, y_valid),\n",
                "                    callbacks=[lr_scheduler])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 97,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 432x288 with 2 Axes>"
                        ]
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": [
                "plt.plot(history.epoch, history.history[\"lr\"], \"bo-\")\n",
                "plt.xlabel(\"Epoch\")\n",
                "plt.ylabel(\"Learning Rate\", color='b')\n",
                "plt.tick_params('y', colors='b')\n",
                "plt.gca().set_xlim(0, n_epochs - 1)\n",
                "plt.grid(True)\n",
                "\n",
                "ax2 = plt.gca().twinx()\n",
                "ax2.plot(history.epoch, history.history[\"val_loss\"], \"r^-\")\n",
                "ax2.set_ylabel('Validation Loss', color='r')\n",
                "ax2.tick_params('y', colors='r')\n",
                "\n",
                "plt.title(\"Reduce LR on Plateau\", fontsize=14)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### tf.keras schedulers\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 98,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4894 - accuracy: 0.8273 - val_loss: 0.4096 - val_accuracy: 0.8600\n",
                        "Epoch 2/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3820 - accuracy: 0.8652 - val_loss: 0.3742 - val_accuracy: 0.8698\n",
                        "Epoch 3/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3487 - accuracy: 0.8764 - val_loss: 0.3736 - val_accuracy: 0.8686\n",
                        "Epoch 4/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3264 - accuracy: 0.8836 - val_loss: 0.3494 - val_accuracy: 0.8796\n",
                        "Epoch 5/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3103 - accuracy: 0.8898 - val_loss: 0.3431 - val_accuracy: 0.8796\n",
                        "Epoch 6/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2957 - accuracy: 0.8951 - val_loss: 0.3410 - val_accuracy: 0.8806\n",
                        "Epoch 7/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2853 - accuracy: 0.8988 - val_loss: 0.3352 - val_accuracy: 0.8804\n",
                        "Epoch 8/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2759 - accuracy: 0.9015 - val_loss: 0.3360 - val_accuracy: 0.8816\n",
                        "Epoch 9/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2677 - accuracy: 0.9053 - val_loss: 0.3260 - val_accuracy: 0.8844\n",
                        "Epoch 10/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2606 - accuracy: 0.9069 - val_loss: 0.3235 - val_accuracy: 0.8862\n",
                        "Epoch 11/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2550 - accuracy: 0.9089 - val_loss: 0.3246 - val_accuracy: 0.8866\n",
                        "Epoch 12/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2495 - accuracy: 0.9124 - val_loss: 0.3295 - val_accuracy: 0.8812\n",
                        "Epoch 13/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2448 - accuracy: 0.9139 - val_loss: 0.3213 - val_accuracy: 0.8858\n",
                        "Epoch 14/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2414 - accuracy: 0.9147 - val_loss: 0.3219 - val_accuracy: 0.8858\n",
                        "Epoch 15/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2374 - accuracy: 0.9167 - val_loss: 0.3204 - val_accuracy: 0.8874\n",
                        "Epoch 16/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2342 - accuracy: 0.9174 - val_loss: 0.3180 - val_accuracy: 0.8888\n",
                        "Epoch 17/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2316 - accuracy: 0.9186 - val_loss: 0.3192 - val_accuracy: 0.8890\n",
                        "Epoch 18/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2290 - accuracy: 0.9197 - val_loss: 0.3165 - val_accuracy: 0.8900\n",
                        "Epoch 19/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2268 - accuracy: 0.9207 - val_loss: 0.3193 - val_accuracy: 0.8892\n",
                        "Epoch 20/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2249 - accuracy: 0.9218 - val_loss: 0.3165 - val_accuracy: 0.8898\n",
                        "Epoch 21/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2228 - accuracy: 0.9226 - val_loss: 0.3176 - val_accuracy: 0.8892\n",
                        "Epoch 22/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2215 - accuracy: 0.9220 - val_loss: 0.3159 - val_accuracy: 0.8912\n",
                        "Epoch 23/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2200 - accuracy: 0.9229 - val_loss: 0.3167 - val_accuracy: 0.8908\n",
                        "Epoch 24/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2187 - accuracy: 0.9239 - val_loss: 0.3162 - val_accuracy: 0.8896\n",
                        "Epoch 25/25\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2178 - accuracy: 0.9244 - val_loss: 0.3161 - val_accuracy: 0.8904\n"
                    ]
                }
            ],
            "source": [
                "model = keras.models.Sequential([\n",
                "    keras.layers.Flatten(input_shape=[28, 28]),\n",
                "    keras.layers.Dense(300,\n",
                "                       activation=\"selu\",\n",
                "                       kernel_initializer=\"lecun_normal\"),\n",
                "    keras.layers.Dense(100,\n",
                "                       activation=\"selu\",\n",
                "                       kernel_initializer=\"lecun_normal\"),\n",
                "    keras.layers.Dense(10, activation=\"softmax\")\n",
                "])\n",
                "s = 20 * len(X_train) // 32  # number of steps in 20 epochs (batch size = 32)\n",
                "learning_rate = keras.optimizers.schedules.ExponentialDecay(0.01, s, 0.1)\n",
                "optimizer = keras.optimizers.SGD(learning_rate)\n",
                "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
                "              optimizer=optimizer,\n",
                "              metrics=[\"accuracy\"])\n",
                "n_epochs = 25\n",
                "history = model.fit(X_train_scaled,\n",
                "                    y_train,\n",
                "                    epochs=n_epochs,\n",
                "                    validation_data=(X_valid_scaled, y_valid))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "For piecewise constant scheduling, try this:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 99,
            "metadata": {},
            "outputs": [],
            "source": [
                "learning_rate = keras.optimizers.schedules.PiecewiseConstantDecay(\n",
                "    boundaries=[5. * n_steps_per_epoch, 15. * n_steps_per_epoch],\n",
                "    values=[0.01, 0.005, 0.001])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1Cycle scheduling\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 100,
            "metadata": {},
            "outputs": [],
            "source": [
                "K = keras.backend\n",
                "\n",
                "\n",
                "class ExponentialLearningRate(keras.callbacks.Callback):\n",
                "\n",
                "    def __init__(self, factor):\n",
                "        self.factor = factor\n",
                "        self.rates = []\n",
                "        self.losses = []\n",
                "\n",
                "    def on_batch_end(self, batch, logs):\n",
                "        self.rates.append(K.get_value(self.model.optimizer.learning_rate))\n",
                "        self.losses.append(logs[\"loss\"])\n",
                "        K.set_value(self.model.optimizer.learning_rate,\n",
                "                    self.model.optimizer.learning_rate * self.factor)\n",
                "\n",
                "\n",
                "def find_learning_rate(model,\n",
                "                       X,\n",
                "                       y,\n",
                "                       epochs=1,\n",
                "                       batch_size=32,\n",
                "                       min_rate=10**-5,\n",
                "                       max_rate=10):\n",
                "    init_weights = model.get_weights()\n",
                "    iterations = math.ceil(len(X) / batch_size) * epochs\n",
                "    factor = np.exp(np.log(max_rate / min_rate) / iterations)\n",
                "    init_lr = K.get_value(model.optimizer.learning_rate)\n",
                "    K.set_value(model.optimizer.learning_rate, min_rate)\n",
                "    exp_lr = ExponentialLearningRate(factor)\n",
                "    history = model.fit(X,\n",
                "                        y,\n",
                "                        epochs=epochs,\n",
                "                        batch_size=batch_size,\n",
                "                        callbacks=[exp_lr])\n",
                "    K.set_value(model.optimizer.learning_rate, init_lr)\n",
                "    model.set_weights(init_weights)\n",
                "    return exp_lr.rates, exp_lr.losses\n",
                "\n",
                "\n",
                "def plot_lr_vs_loss(rates, losses):\n",
                "    plt.plot(rates, losses)\n",
                "    plt.gca().set_xscale('log')\n",
                "    plt.hlines(min(losses), min(rates), max(rates))\n",
                "    plt.axis(\n",
                "        [min(rates),\n",
                "         max(rates),\n",
                "         min(losses), (losses[0] + min(losses)) / 2])\n",
                "    plt.xlabel(\"Learning rate\")\n",
                "    plt.ylabel(\"Loss\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Warning**: In the `on_batch_end()` method, `logs[\"loss\"]` used to contain the batch loss, but in TensorFlow 2.2.0 it was replaced with the mean loss (since the start of the epoch). This explains why the graph below is much smoother than in the book (if you are using TF 2.2 or above). It also means that there is a lag between the moment the batch loss starts exploding and the moment the explosion becomes clear in the graph. So you should choose a slightly smaller learning rate than you would have chosen with the \"noisy\" graph. Alternatively, you can tweak the `ExponentialLearningRate` callback above so it computes the batch loss (based on the current mean loss and the previous mean loss):\n",
                "\n",
                "```python\n",
                "class ExponentialLearningRate(keras.callbacks.Callback):\n",
                "    def __init__(self, factor):\n",
                "        self.factor = factor\n",
                "        self.rates = []\n",
                "        self.losses = []\n",
                "    def on_epoch_begin(self, epoch, logs=None):\n",
                "        self.prev_loss = 0\n",
                "    def on_batch_end(self, batch, logs=None):\n",
                "        batch_loss = logs[\"loss\"] * (batch + 1) - self.prev_loss * batch\n",
                "        self.prev_loss = logs[\"loss\"]\n",
                "        self.rates.append(K.get_value(self.model.optimizer.learning_rate))\n",
                "        self.losses.append(batch_loss)\n",
                "        K.set_value(self.model.optimizer.learning_rate, self.model.optimizer.learning_rate * self.factor)\n",
                "```\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 101,
            "metadata": {},
            "outputs": [],
            "source": [
                "tf.random.set_seed(42)\n",
                "np.random.seed(42)\n",
                "\n",
                "model = keras.models.Sequential([\n",
                "    keras.layers.Flatten(input_shape=[28, 28]),\n",
                "    keras.layers.Dense(300,\n",
                "                       activation=\"selu\",\n",
                "                       kernel_initializer=\"lecun_normal\"),\n",
                "    keras.layers.Dense(100,\n",
                "                       activation=\"selu\",\n",
                "                       kernel_initializer=\"lecun_normal\"),\n",
                "    keras.layers.Dense(10, activation=\"softmax\")\n",
                "])\n",
                "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
                "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
                "              metrics=[\"accuracy\"])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 102,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "430/430 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.3861\n"
                    ]
                },
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 432x288 with 1 Axes>"
                        ]
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": [
                "batch_size = 128\n",
                "rates, losses = find_learning_rate(model,\n",
                "                                   X_train_scaled,\n",
                "                                   y_train,\n",
                "                                   epochs=1,\n",
                "                                   batch_size=batch_size)\n",
                "plot_lr_vs_loss(rates, losses)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 103,
            "metadata": {},
            "outputs": [],
            "source": [
                "class OneCycleScheduler(keras.callbacks.Callback):\n",
                "\n",
                "    def __init__(self,\n",
                "                 iterations,\n",
                "                 max_rate,\n",
                "                 start_rate=None,\n",
                "                 last_iterations=None,\n",
                "                 last_rate=None):\n",
                "        self.iterations = iterations\n",
                "        self.max_rate = max_rate\n",
                "        self.start_rate = start_rate or max_rate / 10\n",
                "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
                "        self.half_iteration = (iterations - self.last_iterations) // 2\n",
                "        self.last_rate = last_rate or self.start_rate / 1000\n",
                "        self.iteration = 0\n",
                "\n",
                "    def _interpolate(self, iter1, iter2, rate1, rate2):\n",
                "        return ((rate2 - rate1) * (self.iteration - iter1) / (iter2 - iter1) +\n",
                "                rate1)\n",
                "\n",
                "    def on_batch_begin(self, batch, logs):\n",
                "        if self.iteration < self.half_iteration:\n",
                "            rate = self._interpolate(0, self.half_iteration, self.start_rate,\n",
                "                                     self.max_rate)\n",
                "        elif self.iteration < 2 * self.half_iteration:\n",
                "            rate = self._interpolate(self.half_iteration,\n",
                "                                     2 * self.half_iteration, self.max_rate,\n",
                "                                     self.start_rate)\n",
                "        else:\n",
                "            rate = self._interpolate(2 * self.half_iteration, self.iterations,\n",
                "                                     self.start_rate, self.last_rate)\n",
                "        self.iteration += 1\n",
                "        K.set_value(self.model.optimizer.learning_rate, rate)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 104,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/25\n",
                        "430/430 [==============================] - 1s 2ms/step - loss: 0.6572 - accuracy: 0.7740 - val_loss: 0.4872 - val_accuracy: 0.8336\n",
                        "Epoch 2/25\n",
                        "430/430 [==============================] - 1s 2ms/step - loss: 0.4581 - accuracy: 0.8395 - val_loss: 0.4275 - val_accuracy: 0.8520\n",
                        "Epoch 3/25\n",
                        "430/430 [==============================] - 1s 2ms/step - loss: 0.4122 - accuracy: 0.8546 - val_loss: 0.4115 - val_accuracy: 0.8588\n",
                        "Epoch 4/25\n",
                        "430/430 [==============================] - 1s 2ms/step - loss: 0.3837 - accuracy: 0.8641 - val_loss: 0.3868 - val_accuracy: 0.8686\n",
                        "Epoch 5/25\n",
                        "430/430 [==============================] - 1s 2ms/step - loss: 0.3639 - accuracy: 0.8717 - val_loss: 0.3765 - val_accuracy: 0.8684\n",
                        "Epoch 6/25\n",
                        "430/430 [==============================] - 1s 2ms/step - loss: 0.3457 - accuracy: 0.8773 - val_loss: 0.3743 - val_accuracy: 0.8708\n",
                        "Epoch 7/25\n",
                        "430/430 [==============================] - 1s 2ms/step - loss: 0.3330 - accuracy: 0.8809 - val_loss: 0.3635 - val_accuracy: 0.8706\n",
                        "Epoch 8/25\n",
                        "430/430 [==============================] - 1s 2ms/step - loss: 0.3184 - accuracy: 0.8860 - val_loss: 0.3957 - val_accuracy: 0.8610\n",
                        "Epoch 9/25\n",
                        "430/430 [==============================] - 1s 2ms/step - loss: 0.3065 - accuracy: 0.8891 - val_loss: 0.3487 - val_accuracy: 0.8772\n",
                        "Epoch 10/25\n",
                        "430/430 [==============================] - 1s 2ms/step - loss: 0.2944 - accuracy: 0.8925 - val_loss: 0.3401 - val_accuracy: 0.8798\n",
                        "Epoch 11/25\n",
                        "430/430 [==============================] - 1s 2ms/step - loss: 0.2839 - accuracy: 0.8957 - val_loss: 0.3464 - val_accuracy: 0.8810\n",
                        "Epoch 12/25\n",
                        "430/430 [==============================] - 1s 2ms/step - loss: 0.2710 - accuracy: 0.9025 - val_loss: 0.3646 - val_accuracy: 0.8702\n",
                        "Epoch 13/25\n",
                        "430/430 [==============================] - 1s 2ms/step - loss: 0.2538 - accuracy: 0.9080 - val_loss: 0.3353 - val_accuracy: 0.8830\n",
                        "Epoch 14/25\n",
                        "430/430 [==============================] - 1s 2ms/step - loss: 0.2406 - accuracy: 0.9136 - val_loss: 0.3458 - val_accuracy: 0.8816\n",
                        "Epoch 15/25\n",
                        "430/430 [==============================] - 1s 2ms/step - loss: 0.2281 - accuracy: 0.9182 - val_loss: 0.3261 - val_accuracy: 0.8838\n",
                        "Epoch 16/25\n",
                        "430/430 [==============================] - 1s 2ms/step - loss: 0.2161 - accuracy: 0.9231 - val_loss: 0.3295 - val_accuracy: 0.8838\n",
                        "Epoch 17/25\n",
                        "430/430 [==============================] - 1s 2ms/step - loss: 0.2064 - accuracy: 0.9263 - val_loss: 0.3348 - val_accuracy: 0.8872\n",
                        "Epoch 18/25\n",
                        "430/430 [==============================] - 1s 2ms/step - loss: 0.1980 - accuracy: 0.9303 - val_loss: 0.3241 - val_accuracy: 0.8906\n",
                        "Epoch 19/25\n",
                        "430/430 [==============================] - 1s 2ms/step - loss: 0.1893 - accuracy: 0.9338 - val_loss: 0.3231 - val_accuracy: 0.8914\n",
                        "Epoch 20/25\n",
                        "430/430 [==============================] - 1s 2ms/step - loss: 0.1822 - accuracy: 0.9369 - val_loss: 0.3223 - val_accuracy: 0.8928\n",
                        "Epoch 21/25\n",
                        "430/430 [==============================] - 1s 2ms/step - loss: 0.1753 - accuracy: 0.9399 - val_loss: 0.3218 - val_accuracy: 0.8926\n",
                        "Epoch 22/25\n",
                        "430/430 [==============================] - 1s 2ms/step - loss: 0.1701 - accuracy: 0.9418 - val_loss: 0.3180 - val_accuracy: 0.8944\n",
                        "Epoch 23/25\n",
                        "430/430 [==============================] - 1s 2ms/step - loss: 0.1655 - accuracy: 0.9437 - val_loss: 0.3185 - val_accuracy: 0.8946\n",
                        "Epoch 24/25\n",
                        "430/430 [==============================] - 1s 2ms/step - loss: 0.1627 - accuracy: 0.9457 - val_loss: 0.3176 - val_accuracy: 0.8940\n",
                        "Epoch 25/25\n",
                        "430/430 [==============================] - 1s 2ms/step - loss: 0.1610 - accuracy: 0.9462 - val_loss: 0.3168 - val_accuracy: 0.8952\n"
                    ]
                }
            ],
            "source": [
                "n_epochs = 25\n",
                "onecycle = OneCycleScheduler(math.ceil(len(X_train) / batch_size) * n_epochs,\n",
                "                             max_rate=0.05)\n",
                "history = model.fit(X_train_scaled,\n",
                "                    y_train,\n",
                "                    epochs=n_epochs,\n",
                "                    batch_size=batch_size,\n",
                "                    validation_data=(X_valid_scaled, y_valid),\n",
                "                    callbacks=[onecycle])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Avoiding Overfitting Through Regularization\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## $\\ell_1$ and $\\ell_2$ regularization\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 105,
            "metadata": {},
            "outputs": [],
            "source": [
                "layer = keras.layers.Dense(100,\n",
                "                           activation=\"elu\",\n",
                "                           kernel_initializer=\"he_normal\",\n",
                "                           kernel_regularizer=keras.regularizers.l2(0.01))\n",
                "# or l1(0.1) for ℓ1 regularization with a factor of 0.1\n",
                "# or l1_l2(0.1, 0.01) for both ℓ1 and ℓ2 regularization, with factors 0.1 and 0.01 respectively"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 106,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/2\n",
                        "1719/1719 [==============================] - 5s 3ms/step - loss: 1.5956 - accuracy: 0.8124 - val_loss: 0.7169 - val_accuracy: 0.8340\n",
                        "Epoch 2/2\n",
                        "1719/1719 [==============================] - 5s 3ms/step - loss: 0.7197 - accuracy: 0.8274 - val_loss: 0.6850 - val_accuracy: 0.8376\n"
                    ]
                }
            ],
            "source": [
                "model = keras.models.Sequential([\n",
                "    keras.layers.Flatten(input_shape=[28, 28]),\n",
                "    keras.layers.Dense(300,\n",
                "                       activation=\"elu\",\n",
                "                       kernel_initializer=\"he_normal\",\n",
                "                       kernel_regularizer=keras.regularizers.l2(0.01)),\n",
                "    keras.layers.Dense(100,\n",
                "                       activation=\"elu\",\n",
                "                       kernel_initializer=\"he_normal\",\n",
                "                       kernel_regularizer=keras.regularizers.l2(0.01)),\n",
                "    keras.layers.Dense(10,\n",
                "                       activation=\"softmax\",\n",
                "                       kernel_regularizer=keras.regularizers.l2(0.01))\n",
                "])\n",
                "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
                "              optimizer=\"nadam\",\n",
                "              metrics=[\"accuracy\"])\n",
                "n_epochs = 2\n",
                "history = model.fit(X_train_scaled,\n",
                "                    y_train,\n",
                "                    epochs=n_epochs,\n",
                "                    validation_data=(X_valid_scaled, y_valid))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 107,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/2\n",
                        "1719/1719 [==============================] - 5s 3ms/step - loss: 1.6313 - accuracy: 0.8113 - val_loss: 0.7218 - val_accuracy: 0.8310\n",
                        "Epoch 2/2\n",
                        "1719/1719 [==============================] - 4s 3ms/step - loss: 0.7187 - accuracy: 0.8273 - val_loss: 0.6826 - val_accuracy: 0.8382\n"
                    ]
                }
            ],
            "source": [
                "from functools import partial\n",
                "\n",
                "RegularizedDense = partial(keras.layers.Dense,\n",
                "                           activation=\"elu\",\n",
                "                           kernel_initializer=\"he_normal\",\n",
                "                           kernel_regularizer=keras.regularizers.l2(0.01))\n",
                "\n",
                "model = keras.models.Sequential([\n",
                "    keras.layers.Flatten(input_shape=[28, 28]),\n",
                "    RegularizedDense(300),\n",
                "    RegularizedDense(100),\n",
                "    RegularizedDense(10, activation=\"softmax\")\n",
                "])\n",
                "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
                "              optimizer=\"nadam\",\n",
                "              metrics=[\"accuracy\"])\n",
                "n_epochs = 2\n",
                "history = model.fit(X_train_scaled,\n",
                "                    y_train,\n",
                "                    epochs=n_epochs,\n",
                "                    validation_data=(X_valid_scaled, y_valid))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Dropout\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 108,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/2\n",
                        "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5838 - accuracy: 0.7997 - val_loss: 0.3730 - val_accuracy: 0.8644\n",
                        "Epoch 2/2\n",
                        "1719/1719 [==============================] - 4s 3ms/step - loss: 0.4209 - accuracy: 0.8443 - val_loss: 0.3395 - val_accuracy: 0.8722\n"
                    ]
                }
            ],
            "source": [
                "model = keras.models.Sequential([\n",
                "    keras.layers.Flatten(input_shape=[28, 28]),\n",
                "    keras.layers.Dropout(rate=0.2),\n",
                "    keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
                "    keras.layers.Dropout(rate=0.2),\n",
                "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
                "    keras.layers.Dropout(rate=0.2),\n",
                "    keras.layers.Dense(10, activation=\"softmax\")\n",
                "])\n",
                "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
                "              optimizer=\"nadam\",\n",
                "              metrics=[\"accuracy\"])\n",
                "n_epochs = 2\n",
                "history = model.fit(X_train_scaled,\n",
                "                    y_train,\n",
                "                    epochs=n_epochs,\n",
                "                    validation_data=(X_valid_scaled, y_valid))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Alpha Dropout\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 109,
            "metadata": {},
            "outputs": [],
            "source": [
                "tf.random.set_seed(42)\n",
                "np.random.seed(42)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 110,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/20\n",
                        "1719/1719 [==============================] - 3s 2ms/step - loss: 0.6617 - accuracy: 0.7611 - val_loss: 0.5756 - val_accuracy: 0.8410\n",
                        "Epoch 2/20\n",
                        "1719/1719 [==============================] - 3s 1ms/step - loss: 0.5547 - accuracy: 0.7970 - val_loss: 0.5404 - val_accuracy: 0.8478\n",
                        "Epoch 3/20\n",
                        "1719/1719 [==============================] - 3s 1ms/step - loss: 0.5254 - accuracy: 0.8060 - val_loss: 0.5018 - val_accuracy: 0.8554\n",
                        "Epoch 4/20\n",
                        "1719/1719 [==============================] - 3s 1ms/step - loss: 0.5047 - accuracy: 0.8131 - val_loss: 0.4773 - val_accuracy: 0.8592\n",
                        "Epoch 5/20\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4926 - accuracy: 0.8167 - val_loss: 0.4651 - val_accuracy: 0.8604\n",
                        "Epoch 6/20\n",
                        "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4839 - accuracy: 0.8200 - val_loss: 0.4851 - val_accuracy: 0.8566\n",
                        "Epoch 7/20\n",
                        "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4717 - accuracy: 0.8248 - val_loss: 0.5079 - val_accuracy: 0.8482\n",
                        "Epoch 8/20\n",
                        "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4643 - accuracy: 0.8289 - val_loss: 0.4548 - val_accuracy: 0.8642\n",
                        "Epoch 9/20\n",
                        "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4614 - accuracy: 0.8294 - val_loss: 0.4327 - val_accuracy: 0.8734\n",
                        "Epoch 10/20\n",
                        "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4526 - accuracy: 0.8316 - val_loss: 0.4435 - val_accuracy: 0.8628\n",
                        "Epoch 11/20\n",
                        "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4481 - accuracy: 0.8341 - val_loss: 0.3992 - val_accuracy: 0.8784\n",
                        "Epoch 12/20\n",
                        "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4428 - accuracy: 0.8345 - val_loss: 0.5319 - val_accuracy: 0.8546\n",
                        "Epoch 13/20\n",
                        "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4429 - accuracy: 0.8350 - val_loss: 0.4156 - val_accuracy: 0.8778\n",
                        "Epoch 14/20\n",
                        "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4377 - accuracy: 0.8379 - val_loss: 0.4621 - val_accuracy: 0.8622\n",
                        "Epoch 15/20\n",
                        "1719/1719 [==============================] - 3s 1ms/step - loss: 0.4323 - accuracy: 0.8394 - val_loss: 0.4527 - val_accuracy: 0.8680\n",
                        "Epoch 16/20\n",
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4307 - accuracy: 0.8401 - val_loss: 0.4325 - val_accuracy: 0.8734\n",
                        "Epoch 17/20\n",
                        "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4290 - accuracy: 0.8417 - val_loss: 0.5064 - val_accuracy: 0.8634\n",
                        "Epoch 18/20\n",
                        "1719/1719 [==============================] - 3s 1ms/step - loss: 0.4275 - accuracy: 0.8404 - val_loss: 0.4738 - val_accuracy: 0.8762\n",
                        "Epoch 19/20\n",
                        "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4245 - accuracy: 0.8421 - val_loss: 0.4723 - val_accuracy: 0.8720\n",
                        "Epoch 20/20\n",
                        "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4184 - accuracy: 0.8435 - val_loss: 0.4269 - val_accuracy: 0.8756\n"
                    ]
                }
            ],
            "source": [
                "model = keras.models.Sequential([\n",
                "    keras.layers.Flatten(input_shape=[28, 28]),\n",
                "    keras.layers.AlphaDropout(rate=0.2),\n",
                "    keras.layers.Dense(300,\n",
                "                       activation=\"selu\",\n",
                "                       kernel_initializer=\"lecun_normal\"),\n",
                "    keras.layers.AlphaDropout(rate=0.2),\n",
                "    keras.layers.Dense(100,\n",
                "                       activation=\"selu\",\n",
                "                       kernel_initializer=\"lecun_normal\"),\n",
                "    keras.layers.AlphaDropout(rate=0.2),\n",
                "    keras.layers.Dense(10, activation=\"softmax\")\n",
                "])\n",
                "optimizer = keras.optimizers.SGD(learning_rate=0.01,\n",
                "                                 momentum=0.9,\n",
                "                                 nesterov=True)\n",
                "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
                "              optimizer=optimizer,\n",
                "              metrics=[\"accuracy\"])\n",
                "n_epochs = 20\n",
                "history = model.fit(X_train_scaled,\n",
                "                    y_train,\n",
                "                    epochs=n_epochs,\n",
                "                    validation_data=(X_valid_scaled, y_valid))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 111,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "313/313 [==============================] - 0s 837us/step - loss: 0.4732 - accuracy: 0.8604\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "[0.473209023475647, 0.8604000210762024]"
                        ]
                    },
                    "execution_count": 111,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "model.evaluate(X_test_scaled, y_test)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 112,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "1719/1719 [==============================] - 1s 623us/step - loss: 0.3458 - accuracy: 0.8834\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "[0.3457886576652527, 0.883400022983551]"
                        ]
                    },
                    "execution_count": 112,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "model.evaluate(X_train_scaled, y_train)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 113,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4183 - accuracy: 0.8439\n"
                    ]
                }
            ],
            "source": [
                "history = model.fit(X_train_scaled, y_train)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## MC Dropout\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 114,
            "metadata": {},
            "outputs": [],
            "source": [
                "tf.random.set_seed(42)\n",
                "np.random.seed(42)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 115,
            "metadata": {},
            "outputs": [],
            "source": [
                "y_probas = np.stack(\n",
                "    [model(X_test_scaled, training=True) for sample in range(100)])\n",
                "y_proba = y_probas.mean(axis=0)\n",
                "y_std = y_probas.std(axis=0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 116,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
                            "      dtype=float32)"
                        ]
                    },
                    "execution_count": 116,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "np.round(model.predict(X_test_scaled[:1]), 2)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 117,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "array([[[0.  , 0.  , 0.  , 0.  , 0.  , 0.67, 0.  , 0.15, 0.  , 0.18]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.38, 0.  , 0.54]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.2 , 0.  , 0.72]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.3 , 0.  , 0.66]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.43, 0.  , 0.26, 0.  , 0.31]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.24, 0.  , 0.56, 0.  , 0.2 ]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.01, 0.  , 0.97]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.89, 0.  , 0.08, 0.  , 0.03]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.45, 0.  , 0.54]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.22, 0.  , 0.75]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.1 , 0.  , 0.07, 0.  , 0.82]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.56, 0.  , 0.13, 0.  , 0.31]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.24, 0.  , 0.  , 0.  , 0.76]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.08, 0.  , 0.9 ]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.41, 0.  , 0.34, 0.  , 0.25]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.37, 0.  , 0.45, 0.  , 0.18]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.94, 0.  , 0.  , 0.  , 0.06]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.36, 0.  , 0.63]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.54, 0.  , 0.07, 0.  , 0.39]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.43, 0.  , 0.43, 0.  , 0.14]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.52, 0.  , 0.34, 0.  , 0.14]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.34, 0.  , 0.31, 0.  , 0.35]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.12, 0.  , 0.85]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.18, 0.  , 0.76]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.03, 0.  , 0.95]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.41, 0.  , 0.56]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.39, 0.  , 0.31, 0.  , 0.29]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.45, 0.  , 0.53]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.86, 0.  , 0.13]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.12, 0.  , 0.86]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.71, 0.  , 0.27]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.74, 0.  , 0.23]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.12, 0.  , 0.18, 0.  , 0.71]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.07, 0.  , 0.91]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.5 , 0.01, 0.41]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.15, 0.  , 0.37, 0.  , 0.48]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.65, 0.  , 0.34]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.11, 0.  , 0.17, 0.  , 0.71]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.03, 0.  , 0.9 ]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.11, 0.  , 0.88]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.19, 0.  , 0.43, 0.  , 0.38]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.59, 0.  , 0.12, 0.  , 0.29]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.31, 0.  , 0.67]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.39, 0.  , 0.58]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.17, 0.  , 0.25, 0.  , 0.58]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.23, 0.  , 0.11, 0.  , 0.67]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.86, 0.  , 0.08]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.93, 0.  , 0.04]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.01, 0.  , 0.96]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.51, 0.  , 0.3 , 0.  , 0.19]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.24, 0.  , 0.71]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.61, 0.  , 0.39]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.15, 0.  , 0.83]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.15, 0.  , 0.29, 0.  , 0.56]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.02, 0.  , 0.95]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.23, 0.  , 0.08, 0.  , 0.69]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.96, 0.  , 0.03]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.15, 0.  , 0.32, 0.  , 0.53]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.29, 0.  , 0.7 ]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.28, 0.  , 0.7 ]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.1 , 0.  , 0.47, 0.  , 0.43]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.09, 0.  , 0.21, 0.  , 0.7 ]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.68, 0.  , 0.02, 0.  , 0.3 ]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.1 , 0.  , 0.36, 0.  , 0.54]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.42, 0.  , 0.57]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.17, 0.  , 0.76, 0.  , 0.06]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.13, 0.  , 0.12, 0.01, 0.74]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.11, 0.  , 0.86]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.34, 0.  , 0.35, 0.04, 0.27]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.  , 0.  , 0.97]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.1 , 0.  , 0.88]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.93, 0.  , 0.01, 0.  , 0.07]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.1 , 0.  , 0.9 ]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.05, 0.  , 0.88]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.09, 0.  , 0.12, 0.  , 0.79]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.2 , 0.  , 0.3 , 0.  , 0.5 ]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.1 , 0.  , 0.57, 0.  , 0.33]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.15, 0.  , 0.36, 0.  , 0.5 ]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.13, 0.  , 0.48, 0.  , 0.4 ]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.43, 0.  , 0.56]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.02, 0.  , 0.97]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.32, 0.  , 0.64]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.07, 0.  , 0.91]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.73, 0.  , 0.03, 0.18, 0.06]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.5 , 0.  , 0.44]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.68, 0.  , 0.01, 0.  , 0.31]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.12, 0.  , 0.88]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.91]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.09, 0.  , 0.88]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.12, 0.  , 0.54, 0.07, 0.27]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.1 , 0.  , 0.06, 0.  , 0.84]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.64, 0.  , 0.16, 0.  , 0.2 ]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.23, 0.  , 0.66, 0.  , 0.12]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.69, 0.  , 0.18, 0.  , 0.13]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.23, 0.  , 0.62, 0.  , 0.16]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
                            "\n",
                            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.29, 0.  , 0.71]]],\n",
                            "      dtype=float32)"
                        ]
                    },
                    "execution_count": 117,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "np.round(y_probas[:, :1], 2)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 118,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.18, 0.  , 0.27, 0.  , 0.55]],\n",
                            "      dtype=float32)"
                        ]
                    },
                    "execution_count": 118,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "np.round(y_proba[:1], 2)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 119,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.23, 0.  , 0.23, 0.02, 0.3 ]],\n",
                            "      dtype=float32)"
                        ]
                    },
                    "execution_count": 119,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "y_std = y_probas.std(axis=0)\n",
                "np.round(y_std[:1], 2)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 120,
            "metadata": {},
            "outputs": [],
            "source": [
                "y_pred = np.argmax(y_proba, axis=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 121,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0.87"
                        ]
                    },
                    "execution_count": 121,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
                "accuracy"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 122,
            "metadata": {},
            "outputs": [],
            "source": [
                "class MCDropout(keras.layers.Dropout):\n",
                "\n",
                "    def call(self, inputs):\n",
                "        return super().call(inputs, training=True)\n",
                "\n",
                "\n",
                "class MCAlphaDropout(keras.layers.AlphaDropout):\n",
                "\n",
                "    def call(self, inputs):\n",
                "        return super().call(inputs, training=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 123,
            "metadata": {},
            "outputs": [],
            "source": [
                "tf.random.set_seed(42)\n",
                "np.random.seed(42)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 124,
            "metadata": {},
            "outputs": [],
            "source": [
                "mc_model = keras.models.Sequential([\n",
                "    MCAlphaDropout(layer.rate)\n",
                "    if isinstance(layer, keras.layers.AlphaDropout) else layer\n",
                "    for layer in model.layers\n",
                "])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 125,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Model: \"sequential_23\"\n",
                        "_________________________________________________________________\n",
                        " Layer (type)                Output Shape              Param #   \n",
                        "=================================================================\n",
                        " flatten_19 (Flatten)        (None, 784)               0         \n",
                        "                                                                 \n",
                        " mc_alpha_dropout (MCAlphaDr  (None, 784)              0         \n",
                        " opout)                                                          \n",
                        "                                                                 \n",
                        " dense_267 (Dense)           (None, 300)               235500    \n",
                        "                                                                 \n",
                        " mc_alpha_dropout_1 (MCAlpha  (None, 300)              0         \n",
                        " Dropout)                                                        \n",
                        "                                                                 \n",
                        " dense_268 (Dense)           (None, 100)               30100     \n",
                        "                                                                 \n",
                        " mc_alpha_dropout_2 (MCAlpha  (None, 100)              0         \n",
                        " Dropout)                                                        \n",
                        "                                                                 \n",
                        " dense_269 (Dense)           (None, 10)                1010      \n",
                        "                                                                 \n",
                        "=================================================================\n",
                        "Total params: 266,610\n",
                        "Trainable params: 266,610\n",
                        "Non-trainable params: 0\n",
                        "_________________________________________________________________\n"
                    ]
                }
            ],
            "source": [
                "mc_model.summary()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 126,
            "metadata": {},
            "outputs": [],
            "source": [
                "optimizer = keras.optimizers.SGD(learning_rate=0.01,\n",
                "                                 momentum=0.9,\n",
                "                                 nesterov=True)\n",
                "mc_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
                "                 optimizer=optimizer,\n",
                "                 metrics=[\"accuracy\"])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 127,
            "metadata": {},
            "outputs": [],
            "source": [
                "mc_model.set_weights(model.get_weights())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now we can use the model with MC Dropout:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 128,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.14, 0.  , 0.29, 0.  , 0.58]],\n",
                            "      dtype=float32)"
                        ]
                    },
                    "execution_count": 128,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "np.round(\n",
                "    np.mean([mc_model.predict(X_test_scaled[:1]) for sample in range(100)],\n",
                "            axis=0), 2)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Max norm\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 129,
            "metadata": {},
            "outputs": [],
            "source": [
                "layer = keras.layers.Dense(100,\n",
                "                           activation=\"selu\",\n",
                "                           kernel_initializer=\"lecun_normal\",\n",
                "                           kernel_constraint=keras.constraints.max_norm(1.))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 130,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/2\n",
                        "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4742 - accuracy: 0.8327 - val_loss: 0.3727 - val_accuracy: 0.8644\n",
                        "Epoch 2/2\n",
                        "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3550 - accuracy: 0.8709 - val_loss: 0.3637 - val_accuracy: 0.8700\n"
                    ]
                }
            ],
            "source": [
                "MaxNormDense = partial(keras.layers.Dense,\n",
                "                       activation=\"selu\",\n",
                "                       kernel_initializer=\"lecun_normal\",\n",
                "                       kernel_constraint=keras.constraints.max_norm(1.))\n",
                "\n",
                "model = keras.models.Sequential([\n",
                "    keras.layers.Flatten(input_shape=[28, 28]),\n",
                "    MaxNormDense(300),\n",
                "    MaxNormDense(100),\n",
                "    keras.layers.Dense(10, activation=\"softmax\")\n",
                "])\n",
                "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
                "              optimizer=\"nadam\",\n",
                "              metrics=[\"accuracy\"])\n",
                "n_epochs = 2\n",
                "history = model.fit(X_train_scaled,\n",
                "                    y_train,\n",
                "                    epochs=n_epochs,\n",
                "                    validation_data=(X_valid_scaled, y_valid))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Exercises\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. to 7.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "See appendix A.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Deep Learning on CIFAR10\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### a.\n",
                "\n",
                "_Exercise: Build a DNN with 20 hidden layers of 100 neurons each (that's too many, but it's the point of this exercise). Use He initialization and the ELU activation function._\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 131,
            "metadata": {},
            "outputs": [],
            "source": [
                "keras.backend.clear_session()\n",
                "tf.random.set_seed(42)\n",
                "np.random.seed(42)\n",
                "\n",
                "model = keras.models.Sequential()\n",
                "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
                "for _ in range(20):\n",
                "    model.add(\n",
                "        keras.layers.Dense(100,\n",
                "                           activation=\"elu\",\n",
                "                           kernel_initializer=\"he_normal\"))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### b.\n",
                "\n",
                "_Exercise: Using Nadam optimization and early stopping, train the network on the CIFAR10 dataset. You can load it with `keras.datasets.cifar10.load_data()`. The dataset is composed of 60,000 32 × 32–pixel color images (50,000 for training, 10,000 for testing) with 10 classes, so you'll need a softmax output layer with 10 neurons. Remember to search for the right learning rate each time you change the model's architecture or hyperparameters._\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's add the output layer to the model:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 132,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's use a Nadam optimizer with a learning rate of 5e-5. I tried learning rates 1e-5, 3e-5, 1e-4, 3e-4, 1e-3, 3e-3 and 1e-2, and I compared their learning curves for 10 epochs each (using the TensorBoard callback, below). The learning rates 3e-5 and 1e-4 were pretty good, so I tried 5e-5, which turned out to be slightly better.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 133,
            "metadata": {},
            "outputs": [],
            "source": [
                "optimizer = keras.optimizers.Nadam(learning_rate=5e-5)\n",
                "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
                "              optimizer=optimizer,\n",
                "              metrics=[\"accuracy\"])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's load the CIFAR10 dataset. We also want to use early stopping, so we need a validation set. Let's use the first 5,000 images of the original training set as the validation set:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 137,
            "metadata": {},
            "outputs": [],
            "source": [
                "# (X_train_full, y_train_full), (X_test,\n",
                "#                                y_test) = keras.datasets.cifar10.load_data()\n",
                "\n",
                "# np.savez(file=\"../../data-handson/cifar10_X.npz\",train=X_train_full, test=X_test)\n",
                "# np.savez(file=\"../../data-handson/cifar10_y.npz\",train=y_train_full, test=y_test)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 138,
            "metadata": {},
            "outputs": [],
            "source": [
                "np.savez(file=\"../../data-handson/cifar10_X.npz\",train=X_train_full, test=X_test)\n",
                "np.savez(file=\"../../data-handson/cifar10_y.npz\",train=y_train_full, test=y_test)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 139,
            "metadata": {},
            "outputs": [],
            "source": [
                "X = np.load(file=\"../../data-handson/cifar10_X.npz\")\n",
                "y = np.load(file=\"../../data-handson/cifar10_y.npz\")\n",
                "X_train_full, X_test = X[\"train\"], X[\"test\"]\n",
                "y_train_full, y_test = y[\"train\"], y[\"test\"]\n",
                "\n",
                "X_train = X_train_full[5000:]\n",
                "y_train = y_train_full[5000:]\n",
                "X_valid = X_train_full[:5000]\n",
                "y_valid = y_train_full[:5000]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now we can create the callbacks we need and train the model:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 140,
            "metadata": {},
            "outputs": [],
            "source": [
                "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
                "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"../../data-handson/my_cifar10_model.h5\",\n",
                "                                                      save_best_only=True)\n",
                "run_index = 1  # increment every time you train the model\n",
                "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\",\n",
                "                          \"run_{:03d}\".format(run_index))\n",
                "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
                "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 141,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "UsageError: Line magic function `%tensorboard` not found.\n"
                    ]
                }
            ],
            "source": [
                "%tensorboard --logdir=./my_cifar10_logs --port=6006"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 142,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/100\n",
                        "1407/1407 [==============================] - 9s 5ms/step - loss: 4.1241 - accuracy: 0.1623 - val_loss: 2.1621 - val_accuracy: 0.2274\n",
                        "Epoch 2/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 2.0811 - accuracy: 0.2371 - val_loss: 2.0416 - val_accuracy: 0.2370\n",
                        "Epoch 3/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.9693 - accuracy: 0.2744 - val_loss: 1.9953 - val_accuracy: 0.2666\n",
                        "Epoch 4/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.8891 - accuracy: 0.3052 - val_loss: 1.9138 - val_accuracy: 0.3148\n",
                        "Epoch 5/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.8251 - accuracy: 0.3308 - val_loss: 1.8167 - val_accuracy: 0.3272\n",
                        "Epoch 6/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.7690 - accuracy: 0.3538 - val_loss: 1.7353 - val_accuracy: 0.3656\n",
                        "Epoch 7/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.7210 - accuracy: 0.3725 - val_loss: 1.7171 - val_accuracy: 0.3774\n",
                        "Epoch 8/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.6813 - accuracy: 0.3895 - val_loss: 1.6712 - val_accuracy: 0.3986\n",
                        "Epoch 9/100\n",
                        "1407/1407 [==============================] - 8s 5ms/step - loss: 1.6474 - accuracy: 0.4033 - val_loss: 1.6913 - val_accuracy: 0.3922\n",
                        "Epoch 10/100\n",
                        "1407/1407 [==============================] - 8s 5ms/step - loss: 1.6218 - accuracy: 0.4126 - val_loss: 1.6735 - val_accuracy: 0.3946\n",
                        "Epoch 11/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.5977 - accuracy: 0.4215 - val_loss: 1.6874 - val_accuracy: 0.3890\n",
                        "Epoch 12/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.5738 - accuracy: 0.4324 - val_loss: 1.6497 - val_accuracy: 0.4100\n",
                        "Epoch 13/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.5547 - accuracy: 0.4376 - val_loss: 1.6364 - val_accuracy: 0.4102\n",
                        "Epoch 14/100\n",
                        "1407/1407 [==============================] - 8s 5ms/step - loss: 1.5336 - accuracy: 0.4472 - val_loss: 1.6028 - val_accuracy: 0.4174\n",
                        "Epoch 15/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.5184 - accuracy: 0.4510 - val_loss: 1.5883 - val_accuracy: 0.4312\n",
                        "Epoch 16/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.4998 - accuracy: 0.4571 - val_loss: 1.5757 - val_accuracy: 0.4378\n",
                        "Epoch 17/100\n",
                        "1407/1407 [==============================] - 8s 5ms/step - loss: 1.4879 - accuracy: 0.4630 - val_loss: 1.5614 - val_accuracy: 0.4406\n",
                        "Epoch 18/100\n",
                        "1407/1407 [==============================] - 8s 5ms/step - loss: 1.4706 - accuracy: 0.4692 - val_loss: 1.5580 - val_accuracy: 0.4406\n",
                        "Epoch 19/100\n",
                        "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4545 - accuracy: 0.4758 - val_loss: 1.5592 - val_accuracy: 0.4484\n",
                        "Epoch 20/100\n",
                        "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4444 - accuracy: 0.4777 - val_loss: 1.5625 - val_accuracy: 0.4406\n",
                        "Epoch 21/100\n",
                        "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4328 - accuracy: 0.4838 - val_loss: 1.5409 - val_accuracy: 0.4494\n",
                        "Epoch 22/100\n",
                        "1407/1407 [==============================] - 8s 5ms/step - loss: 1.4183 - accuracy: 0.4904 - val_loss: 1.5260 - val_accuracy: 0.4562\n",
                        "Epoch 23/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.4054 - accuracy: 0.4937 - val_loss: 1.5415 - val_accuracy: 0.4506\n",
                        "Epoch 24/100\n",
                        "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3905 - accuracy: 0.5004 - val_loss: 1.5488 - val_accuracy: 0.4480\n",
                        "Epoch 25/100\n",
                        "1407/1407 [==============================] - 8s 5ms/step - loss: 1.3832 - accuracy: 0.5021 - val_loss: 1.5390 - val_accuracy: 0.4520\n",
                        "Epoch 26/100\n",
                        "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3716 - accuracy: 0.5039 - val_loss: 1.5417 - val_accuracy: 0.4530\n",
                        "Epoch 27/100\n",
                        "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3605 - accuracy: 0.5093 - val_loss: 1.4996 - val_accuracy: 0.4650\n",
                        "Epoch 28/100\n",
                        "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3524 - accuracy: 0.5121 - val_loss: 1.5306 - val_accuracy: 0.4522\n",
                        "Epoch 29/100\n",
                        "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3428 - accuracy: 0.5147 - val_loss: 1.5081 - val_accuracy: 0.4696\n",
                        "Epoch 30/100\n",
                        "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3320 - accuracy: 0.5194 - val_loss: 1.5242 - val_accuracy: 0.4646\n",
                        "Epoch 31/100\n",
                        "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3226 - accuracy: 0.5238 - val_loss: 1.5495 - val_accuracy: 0.4656\n",
                        "Epoch 32/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3144 - accuracy: 0.5262 - val_loss: 1.5211 - val_accuracy: 0.4714\n",
                        "Epoch 33/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3042 - accuracy: 0.5293 - val_loss: 1.5292 - val_accuracy: 0.4658\n",
                        "Epoch 34/100\n",
                        "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2978 - accuracy: 0.5315 - val_loss: 1.5525 - val_accuracy: 0.4636\n",
                        "Epoch 35/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2915 - accuracy: 0.5349 - val_loss: 1.5569 - val_accuracy: 0.4584\n",
                        "Epoch 36/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2826 - accuracy: 0.5373 - val_loss: 1.5407 - val_accuracy: 0.4666\n",
                        "Epoch 37/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2717 - accuracy: 0.5421 - val_loss: 1.4998 - val_accuracy: 0.4746\n",
                        "Epoch 38/100\n",
                        "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2652 - accuracy: 0.5438 - val_loss: 1.5178 - val_accuracy: 0.4748\n",
                        "Epoch 39/100\n",
                        "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2566 - accuracy: 0.5474 - val_loss: 1.5083 - val_accuracy: 0.4744\n",
                        "Epoch 40/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2458 - accuracy: 0.5501 - val_loss: 1.5317 - val_accuracy: 0.4648\n",
                        "Epoch 41/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2393 - accuracy: 0.5536 - val_loss: 1.5448 - val_accuracy: 0.4778\n",
                        "Epoch 42/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2309 - accuracy: 0.5582 - val_loss: 1.5342 - val_accuracy: 0.4768\n",
                        "Epoch 43/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2234 - accuracy: 0.5594 - val_loss: 1.5436 - val_accuracy: 0.4652\n",
                        "Epoch 44/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2168 - accuracy: 0.5613 - val_loss: 1.5663 - val_accuracy: 0.4608\n",
                        "Epoch 45/100\n",
                        "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2051 - accuracy: 0.5631 - val_loss: 1.5444 - val_accuracy: 0.4748\n",
                        "Epoch 46/100\n",
                        "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2026 - accuracy: 0.5640 - val_loss: 1.5300 - val_accuracy: 0.4804\n",
                        "Epoch 47/100\n",
                        "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1958 - accuracy: 0.5684 - val_loss: 1.5465 - val_accuracy: 0.4708\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "<keras.callbacks.History at 0x2e4718b20>"
                        ]
                    },
                    "execution_count": 142,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "model.fit(X_train,\n",
                "          y_train,\n",
                "          epochs=100,\n",
                "          validation_data=(X_valid, y_valid),\n",
                "          callbacks=callbacks)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 144,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "157/157 [==============================] - 0s 2ms/step - loss: 1.5883 - accuracy: 0.4312\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "[1.5882885456085205, 0.4311999976634979]"
                        ]
                    },
                    "execution_count": 144,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "model = keras.models.load_model(\"../../data-handson/my_cifar10_model.h5\")\n",
                "model.evaluate(X_valid, y_valid)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The model with the lowest validation loss gets about 47.6% accuracy on the validation set. It took 27 epochs to reach the lowest validation loss, with roughly 8 seconds per epoch on my laptop (without a GPU). Let's see if we can improve performance using Batch Normalization.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### c.\n",
                "\n",
                "_Exercise: Now try adding Batch Normalization and compare the learning curves: Is it converging faster than before? Does it produce a better model? How does it affect training speed?_\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The code below is very similar to the code above, with a few changes:\n",
                "\n",
                "- I added a BN layer after every Dense layer (before the activation function), except for the output layer. I also added a BN layer before the first hidden layer.\n",
                "- I changed the learning rate to 5e-4. I experimented with 1e-5, 3e-5, 5e-5, 1e-4, 3e-4, 5e-4, 1e-3 and 3e-3, and I chose the one with the best validation performance after 20 epochs.\n",
                "- I renamed the run directories to run*bn*\\* and the model file name to my_cifar10_bn_model.h5.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 145,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/100\n",
                        "1407/1407 [==============================] - 14s 8ms/step - loss: 1.8445 - accuracy: 0.3407 - val_loss: 1.6620 - val_accuracy: 0.4112\n",
                        "Epoch 2/100\n",
                        "1407/1407 [==============================] - 11s 8ms/step - loss: 1.6699 - accuracy: 0.4064 - val_loss: 1.5882 - val_accuracy: 0.4332\n",
                        "Epoch 3/100\n",
                        "1407/1407 [==============================] - 12s 8ms/step - loss: 1.5999 - accuracy: 0.4317 - val_loss: 1.5354 - val_accuracy: 0.4436\n",
                        "Epoch 4/100\n",
                        "1407/1407 [==============================] - 11s 8ms/step - loss: 1.5518 - accuracy: 0.4461 - val_loss: 1.4975 - val_accuracy: 0.4688\n",
                        "Epoch 5/100\n",
                        "1407/1407 [==============================] - 11s 8ms/step - loss: 1.5048 - accuracy: 0.4673 - val_loss: 1.4609 - val_accuracy: 0.4716\n",
                        "Epoch 6/100\n",
                        "1407/1407 [==============================] - 11s 8ms/step - loss: 1.4677 - accuracy: 0.4798 - val_loss: 1.4237 - val_accuracy: 0.4918\n",
                        "Epoch 7/100\n",
                        "1407/1407 [==============================] - 11s 8ms/step - loss: 1.4351 - accuracy: 0.4903 - val_loss: 1.4177 - val_accuracy: 0.4976\n",
                        "Epoch 8/100\n",
                        "1407/1407 [==============================] - 11s 8ms/step - loss: 1.4057 - accuracy: 0.5014 - val_loss: 1.3740 - val_accuracy: 0.5036\n",
                        "Epoch 9/100\n",
                        "1407/1407 [==============================] - 11s 8ms/step - loss: 1.3822 - accuracy: 0.5134 - val_loss: 1.3768 - val_accuracy: 0.5116\n",
                        "Epoch 10/100\n",
                        "1407/1407 [==============================] - 11s 8ms/step - loss: 1.3596 - accuracy: 0.5188 - val_loss: 1.3474 - val_accuracy: 0.5234\n",
                        "Epoch 11/100\n",
                        "1407/1407 [==============================] - 11s 8ms/step - loss: 1.3426 - accuracy: 0.5234 - val_loss: 1.3452 - val_accuracy: 0.5254\n",
                        "Epoch 12/100\n",
                        "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3165 - accuracy: 0.5354 - val_loss: 1.3739 - val_accuracy: 0.5088\n",
                        "Epoch 13/100\n",
                        "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3030 - accuracy: 0.5388 - val_loss: 1.4007 - val_accuracy: 0.5092\n",
                        "Epoch 14/100\n",
                        "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2851 - accuracy: 0.5452 - val_loss: 1.3448 - val_accuracy: 0.5292\n",
                        "Epoch 15/100\n",
                        "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2656 - accuracy: 0.5528 - val_loss: 1.3660 - val_accuracy: 0.5270\n",
                        "Epoch 16/100\n",
                        "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2546 - accuracy: 0.5579 - val_loss: 1.3590 - val_accuracy: 0.5276\n",
                        "Epoch 17/100\n",
                        "1407/1407 [==============================] - 11s 8ms/step - loss: 1.2365 - accuracy: 0.5629 - val_loss: 1.3229 - val_accuracy: 0.5392\n",
                        "Epoch 18/100\n",
                        "1407/1407 [==============================] - 11s 8ms/step - loss: 1.2203 - accuracy: 0.5681 - val_loss: 1.3354 - val_accuracy: 0.5322\n",
                        "Epoch 19/100\n",
                        "1407/1407 [==============================] - 11s 8ms/step - loss: 1.2050 - accuracy: 0.5744 - val_loss: 1.3419 - val_accuracy: 0.5314\n",
                        "Epoch 20/100\n",
                        "1407/1407 [==============================] - 11s 8ms/step - loss: 1.1945 - accuracy: 0.5787 - val_loss: 1.3591 - val_accuracy: 0.5286\n",
                        "Epoch 21/100\n",
                        "1407/1407 [==============================] - 11s 8ms/step - loss: 1.1784 - accuracy: 0.5843 - val_loss: 1.3647 - val_accuracy: 0.5264\n",
                        "Epoch 22/100\n",
                        "1407/1407 [==============================] - 11s 8ms/step - loss: 1.1626 - accuracy: 0.5888 - val_loss: 1.3371 - val_accuracy: 0.5448\n",
                        "Epoch 23/100\n",
                        "1407/1407 [==============================] - 11s 8ms/step - loss: 1.1553 - accuracy: 0.5957 - val_loss: 1.3271 - val_accuracy: 0.5402\n",
                        "Epoch 24/100\n",
                        "1407/1407 [==============================] - 11s 8ms/step - loss: 1.1390 - accuracy: 0.5977 - val_loss: 1.3377 - val_accuracy: 0.5360\n",
                        "Epoch 25/100\n",
                        "1407/1407 [==============================] - 11s 8ms/step - loss: 1.1280 - accuracy: 0.6009 - val_loss: 1.3331 - val_accuracy: 0.5428\n",
                        "Epoch 26/100\n",
                        "1407/1407 [==============================] - 11s 8ms/step - loss: 1.1149 - accuracy: 0.6053 - val_loss: 1.3298 - val_accuracy: 0.5408\n",
                        "Epoch 27/100\n",
                        "1407/1407 [==============================] - 11s 8ms/step - loss: 1.1021 - accuracy: 0.6113 - val_loss: 1.3466 - val_accuracy: 0.5384\n",
                        "Epoch 28/100\n",
                        "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0986 - accuracy: 0.6140 - val_loss: 1.3487 - val_accuracy: 0.5314\n",
                        "Epoch 29/100\n",
                        "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0820 - accuracy: 0.6185 - val_loss: 1.3278 - val_accuracy: 0.5526\n",
                        "Epoch 30/100\n",
                        "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0721 - accuracy: 0.6216 - val_loss: 1.3590 - val_accuracy: 0.5404\n",
                        "Epoch 31/100\n",
                        "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0613 - accuracy: 0.6258 - val_loss: 1.3785 - val_accuracy: 0.5376\n",
                        "Epoch 32/100\n",
                        "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0531 - accuracy: 0.6276 - val_loss: 1.3677 - val_accuracy: 0.5406\n",
                        "Epoch 33/100\n",
                        "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0395 - accuracy: 0.6318 - val_loss: 1.3334 - val_accuracy: 0.5564\n",
                        "Epoch 34/100\n",
                        "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0361 - accuracy: 0.6348 - val_loss: 1.3385 - val_accuracy: 0.5454\n",
                        "Epoch 35/100\n",
                        "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0214 - accuracy: 0.6425 - val_loss: 1.3534 - val_accuracy: 0.5380\n",
                        "Epoch 36/100\n",
                        "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0143 - accuracy: 0.6416 - val_loss: 1.3487 - val_accuracy: 0.5434\n",
                        "Epoch 37/100\n",
                        "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0015 - accuracy: 0.6466 - val_loss: 1.3739 - val_accuracy: 0.5364\n",
                        "157/157 [==============================] - 0s 2ms/step - loss: 1.3229 - accuracy: 0.5392\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "[1.3228894472122192, 0.5392000079154968]"
                        ]
                    },
                    "execution_count": 145,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "keras.backend.clear_session()\n",
                "tf.random.set_seed(42)\n",
                "np.random.seed(42)\n",
                "\n",
                "model = keras.models.Sequential()\n",
                "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
                "model.add(keras.layers.BatchNormalization())\n",
                "for _ in range(20):\n",
                "    model.add(keras.layers.Dense(100, kernel_initializer=\"he_normal\"))\n",
                "    model.add(keras.layers.BatchNormalization())\n",
                "    model.add(keras.layers.Activation(\"elu\"))\n",
                "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
                "\n",
                "optimizer = keras.optimizers.Nadam(learning_rate=5e-4)\n",
                "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
                "              optimizer=optimizer,\n",
                "              metrics=[\"accuracy\"])\n",
                "\n",
                "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
                "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"../../data-handson/my_cifar10_bn_model.h5\",\n",
                "                                                      save_best_only=True)\n",
                "run_index = 1  # increment every time you train the model\n",
                "run_logdir = os.path.join(os.curdir, \"../../data-handson/my_cifar10_logs\",\n",
                "                          \"run_bn_{:03d}\".format(run_index))\n",
                "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
                "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
                "\n",
                "model.fit(X_train,\n",
                "          y_train,\n",
                "          epochs=100,\n",
                "          validation_data=(X_valid, y_valid),\n",
                "          callbacks=callbacks)\n",
                "\n",
                "model = keras.models.load_model(\"../../data-handson/my_cifar10_bn_model.h5\")\n",
                "model.evaluate(X_valid, y_valid)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- _Is the model converging faster than before?_ Much faster! The previous model took 27 epochs to reach the lowest validation loss, while the new model achieved that same loss in just 5 epochs and continued to make progress until the 16th epoch. The BN layers stabilized training and allowed us to use a much larger learning rate, so convergence was faster.\n",
                "- _Does BN produce a better model?_ Yes! The final model is also much better, with 54.0% accuracy instead of 47.6%. It's still not a very good model, but at least it's much better than before (a Convolutional Neural Network would do much better, but that's a different topic, see chapter 14).\n",
                "- _How does BN affect training speed?_ Although the model converged much faster, each epoch took about 12s instead of 8s, because of the extra computations required by the BN layers. But overall the training time (wall time) was shortened significantly!\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### d.\n",
                "\n",
                "_Exercise: Try replacing Batch Normalization with SELU, and make the necessary adjustements to ensure the network self-normalizes (i.e., standardize the input features, use LeCun normal initialization, make sure the DNN contains only a sequence of dense layers, etc.)._\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 146,
            "metadata": {
                "scrolled": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/100\n",
                        "1407/1407 [==============================] - 8s 5ms/step - loss: 1.9399 - accuracy: 0.3068 - val_loss: 1.8540 - val_accuracy: 0.3296\n",
                        "Epoch 2/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.7265 - accuracy: 0.3917 - val_loss: 1.7387 - val_accuracy: 0.3720\n",
                        "Epoch 3/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.6322 - accuracy: 0.4242 - val_loss: 1.6719 - val_accuracy: 0.3968\n",
                        "Epoch 4/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.5648 - accuracy: 0.4495 - val_loss: 1.5929 - val_accuracy: 0.4472\n",
                        "Epoch 5/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.5059 - accuracy: 0.4709 - val_loss: 1.5796 - val_accuracy: 0.4404\n",
                        "Epoch 6/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.4579 - accuracy: 0.4906 - val_loss: 1.5059 - val_accuracy: 0.4616\n",
                        "Epoch 7/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.4162 - accuracy: 0.5058 - val_loss: 1.5591 - val_accuracy: 0.4546\n",
                        "Epoch 8/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3779 - accuracy: 0.5213 - val_loss: 1.4922 - val_accuracy: 0.4838\n",
                        "Epoch 9/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3380 - accuracy: 0.5346 - val_loss: 1.4889 - val_accuracy: 0.4710\n",
                        "Epoch 10/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3058 - accuracy: 0.5485 - val_loss: 1.4988 - val_accuracy: 0.4888\n",
                        "Epoch 11/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2745 - accuracy: 0.5593 - val_loss: 1.5353 - val_accuracy: 0.4834\n",
                        "Epoch 12/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2502 - accuracy: 0.5701 - val_loss: 1.5079 - val_accuracy: 0.4894\n",
                        "Epoch 13/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2235 - accuracy: 0.5777 - val_loss: 1.4631 - val_accuracy: 0.5060\n",
                        "Epoch 14/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2572 - accuracy: 0.5639 - val_loss: 1.4873 - val_accuracy: 0.4946\n",
                        "Epoch 15/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1784 - accuracy: 0.5884 - val_loss: 1.5619 - val_accuracy: 0.4860\n",
                        "Epoch 16/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1557 - accuracy: 0.6016 - val_loss: 1.5122 - val_accuracy: 0.5078\n",
                        "Epoch 17/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1371 - accuracy: 0.6068 - val_loss: 1.5103 - val_accuracy: 0.4974\n",
                        "Epoch 18/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1197 - accuracy: 0.6158 - val_loss: 1.5140 - val_accuracy: 0.5004\n",
                        "Epoch 19/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1062 - accuracy: 0.6173 - val_loss: 1.5575 - val_accuracy: 0.5016\n",
                        "Epoch 20/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.0815 - accuracy: 0.6278 - val_loss: 1.5543 - val_accuracy: 0.5016\n",
                        "Epoch 21/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.0614 - accuracy: 0.6350 - val_loss: 1.5339 - val_accuracy: 0.5092\n",
                        "Epoch 22/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.0456 - accuracy: 0.6417 - val_loss: 1.5833 - val_accuracy: 0.5032\n",
                        "Epoch 23/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.0269 - accuracy: 0.6479 - val_loss: 1.5924 - val_accuracy: 0.4802\n",
                        "Epoch 24/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.0130 - accuracy: 0.6542 - val_loss: 1.5812 - val_accuracy: 0.5042\n",
                        "Epoch 25/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 0.9941 - accuracy: 0.6608 - val_loss: 1.5906 - val_accuracy: 0.5040\n",
                        "Epoch 26/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 0.9838 - accuracy: 0.6640 - val_loss: 1.6282 - val_accuracy: 0.4908\n",
                        "Epoch 27/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 0.9567 - accuracy: 0.6733 - val_loss: 1.5997 - val_accuracy: 0.5004\n",
                        "Epoch 28/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 0.9470 - accuracy: 0.6808 - val_loss: 1.6332 - val_accuracy: 0.4896\n",
                        "Epoch 29/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 0.9372 - accuracy: 0.6806 - val_loss: 1.6265 - val_accuracy: 0.4934\n",
                        "Epoch 30/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 0.9345 - accuracy: 0.6835 - val_loss: 1.6173 - val_accuracy: 0.4986\n",
                        "Epoch 31/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 0.9085 - accuracy: 0.6917 - val_loss: 1.6441 - val_accuracy: 0.4994\n",
                        "Epoch 32/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 0.8894 - accuracy: 0.6974 - val_loss: 1.6906 - val_accuracy: 0.5020\n",
                        "Epoch 33/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.0264 - accuracy: 0.6528 - val_loss: 1.5828 - val_accuracy: 0.4878\n",
                        "157/157 [==============================] - 0s 1ms/step - loss: 1.4631 - accuracy: 0.5060\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "[1.4630765914916992, 0.5059999823570251]"
                        ]
                    },
                    "execution_count": 146,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "keras.backend.clear_session()\n",
                "tf.random.set_seed(42)\n",
                "np.random.seed(42)\n",
                "\n",
                "model = keras.models.Sequential()\n",
                "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
                "for _ in range(20):\n",
                "    model.add(\n",
                "        keras.layers.Dense(100,\n",
                "                           kernel_initializer=\"lecun_normal\",\n",
                "                           activation=\"selu\"))\n",
                "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
                "\n",
                "optimizer = keras.optimizers.Nadam(learning_rate=7e-4)\n",
                "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
                "              optimizer=optimizer,\n",
                "              metrics=[\"accuracy\"])\n",
                "\n",
                "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
                "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
                "    \"../../data-handson/my_cifar10_selu_model.h5\", save_best_only=True)\n",
                "run_index = 1  # increment every time you train the model\n",
                "run_logdir = os.path.join(os.curdir, \"../../data-handson/my_cifar10_logs\",\n",
                "                          \"run_selu_{:03d}\".format(run_index))\n",
                "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
                "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
                "\n",
                "X_means = X_train.mean(axis=0)\n",
                "X_stds = X_train.std(axis=0)\n",
                "X_train_scaled = (X_train - X_means) / X_stds\n",
                "X_valid_scaled = (X_valid - X_means) / X_stds\n",
                "X_test_scaled = (X_test - X_means) / X_stds\n",
                "\n",
                "model.fit(X_train_scaled,\n",
                "          y_train,\n",
                "          epochs=100,\n",
                "          validation_data=(X_valid_scaled, y_valid),\n",
                "          callbacks=callbacks)\n",
                "\n",
                "model = keras.models.load_model(\"../../data-handson/my_cifar10_selu_model.h5\")\n",
                "model.evaluate(X_valid_scaled, y_valid)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 147,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "157/157 [==============================] - 0s 1ms/step - loss: 1.4631 - accuracy: 0.5060\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "[1.4630765914916992, 0.5059999823570251]"
                        ]
                    },
                    "execution_count": 147,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "model = keras.models.load_model(\"../../data-handson/my_cifar10_selu_model.h5\")\n",
                "model.evaluate(X_valid_scaled, y_valid)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We get 47.9% accuracy, which is not much better than the original model (47.6%), and not as good as the model using batch normalization (54.0%). However, convergence was almost as fast as with the BN model, plus each epoch took only 7 seconds. So it's by far the fastest model to train so far.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### e.\n",
                "\n",
                "_Exercise: Try regularizing the model with alpha dropout. Then, without retraining your model, see if you can achieve better accuracy using MC Dropout._\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 148,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/100\n",
                        "1407/1407 [==============================] - 8s 5ms/step - loss: 1.8856 - accuracy: 0.3306 - val_loss: 1.7551 - val_accuracy: 0.3850\n",
                        "Epoch 2/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.6547 - accuracy: 0.4170 - val_loss: 1.6838 - val_accuracy: 0.3964\n",
                        "Epoch 3/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.5662 - accuracy: 0.4476 - val_loss: 1.6039 - val_accuracy: 0.4368\n",
                        "Epoch 4/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.5032 - accuracy: 0.4722 - val_loss: 1.6108 - val_accuracy: 0.4398\n",
                        "Epoch 5/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.4466 - accuracy: 0.4938 - val_loss: 1.6110 - val_accuracy: 0.4460\n",
                        "Epoch 6/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3984 - accuracy: 0.5127 - val_loss: 1.5438 - val_accuracy: 0.4692\n",
                        "Epoch 7/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3589 - accuracy: 0.5272 - val_loss: 1.5600 - val_accuracy: 0.4816\n",
                        "Epoch 8/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3137 - accuracy: 0.5452 - val_loss: 1.4837 - val_accuracy: 0.4940\n",
                        "Epoch 9/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2810 - accuracy: 0.5546 - val_loss: 1.4976 - val_accuracy: 0.4954\n",
                        "Epoch 10/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2463 - accuracy: 0.5675 - val_loss: 1.5516 - val_accuracy: 0.4922\n",
                        "Epoch 11/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2199 - accuracy: 0.5777 - val_loss: 1.5299 - val_accuracy: 0.5006\n",
                        "Epoch 12/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1900 - accuracy: 0.5915 - val_loss: 1.5229 - val_accuracy: 0.4988\n",
                        "Epoch 13/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1591 - accuracy: 0.5990 - val_loss: 1.5908 - val_accuracy: 0.5078\n",
                        "Epoch 14/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1335 - accuracy: 0.6084 - val_loss: 1.5485 - val_accuracy: 0.5024\n",
                        "Epoch 15/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1075 - accuracy: 0.6203 - val_loss: 1.5894 - val_accuracy: 0.4978\n",
                        "Epoch 16/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.0835 - accuracy: 0.6296 - val_loss: 1.6208 - val_accuracy: 0.5050\n",
                        "Epoch 17/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.0666 - accuracy: 0.6326 - val_loss: 1.6244 - val_accuracy: 0.5120\n",
                        "Epoch 18/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.0433 - accuracy: 0.6441 - val_loss: 1.6346 - val_accuracy: 0.5056\n",
                        "Epoch 19/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.0239 - accuracy: 0.6521 - val_loss: 1.6729 - val_accuracy: 0.5092\n",
                        "Epoch 20/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 1.0013 - accuracy: 0.6591 - val_loss: 1.6498 - val_accuracy: 0.5096\n",
                        "Epoch 21/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 0.9817 - accuracy: 0.6690 - val_loss: 1.6921 - val_accuracy: 0.5152\n",
                        "Epoch 22/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 0.9599 - accuracy: 0.6724 - val_loss: 1.7799 - val_accuracy: 0.5024\n",
                        "Epoch 23/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 0.9411 - accuracy: 0.6770 - val_loss: 1.7015 - val_accuracy: 0.5040\n",
                        "Epoch 24/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 0.9307 - accuracy: 0.6848 - val_loss: 1.6887 - val_accuracy: 0.5044\n",
                        "Epoch 25/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 0.9041 - accuracy: 0.6917 - val_loss: 1.8542 - val_accuracy: 0.5006\n",
                        "Epoch 26/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 0.8945 - accuracy: 0.6955 - val_loss: 1.8414 - val_accuracy: 0.4944\n",
                        "Epoch 27/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 0.8802 - accuracy: 0.7028 - val_loss: 1.7563 - val_accuracy: 0.5048\n",
                        "Epoch 28/100\n",
                        "1407/1407 [==============================] - 7s 5ms/step - loss: 0.8691 - accuracy: 0.7082 - val_loss: 1.7597 - val_accuracy: 0.4910\n",
                        "157/157 [==============================] - 0s 1ms/step - loss: 1.4837 - accuracy: 0.4940\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "[1.4836994409561157, 0.49399998784065247]"
                        ]
                    },
                    "execution_count": 148,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "keras.backend.clear_session()\n",
                "tf.random.set_seed(42)\n",
                "np.random.seed(42)\n",
                "\n",
                "model = keras.models.Sequential()\n",
                "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
                "for _ in range(20):\n",
                "    model.add(\n",
                "        keras.layers.Dense(100,\n",
                "                           kernel_initializer=\"lecun_normal\",\n",
                "                           activation=\"selu\"))\n",
                "\n",
                "model.add(keras.layers.AlphaDropout(rate=0.1))\n",
                "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
                "\n",
                "optimizer = keras.optimizers.Nadam(learning_rate=5e-4)\n",
                "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
                "              optimizer=optimizer,\n",
                "              metrics=[\"accuracy\"])\n",
                "\n",
                "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
                "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
                "    \"../../data-handson/my_cifar10_alpha_dropout_model.h5\",\n",
                "    save_best_only=True)\n",
                "run_index = 1  # increment every time you train the model\n",
                "run_logdir = os.path.join(os.curdir, \"../../data-handson/my_cifar10_logs\",\n",
                "                          \"run_alpha_dropout_{:03d}\".format(run_index))\n",
                "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
                "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
                "\n",
                "X_means = X_train.mean(axis=0)\n",
                "X_stds = X_train.std(axis=0)\n",
                "X_train_scaled = (X_train - X_means) / X_stds\n",
                "X_valid_scaled = (X_valid - X_means) / X_stds\n",
                "X_test_scaled = (X_test - X_means) / X_stds\n",
                "\n",
                "model.fit(X_train_scaled,\n",
                "          y_train,\n",
                "          epochs=100,\n",
                "          validation_data=(X_valid_scaled, y_valid),\n",
                "          callbacks=callbacks)\n",
                "\n",
                "model = keras.models.load_model(\n",
                "    \"../../data-handson/my_cifar10_alpha_dropout_model.h5\")\n",
                "model.evaluate(X_valid_scaled, y_valid)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The model reaches 48.9% accuracy on the validation set. That's very slightly better than without dropout (47.6%). With an extensive hyperparameter search, it might be possible to do better (I tried dropout rates of 5%, 10%, 20% and 40%, and learning rates 1e-4, 3e-4, 5e-4, and 1e-3), but probably not much better in this case.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's use MC Dropout now. We will need the `MCAlphaDropout` class we used earlier, so let's just copy it here for convenience:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 149,
            "metadata": {},
            "outputs": [],
            "source": [
                "class MCAlphaDropout(keras.layers.AlphaDropout):\n",
                "\n",
                "    def call(self, inputs):\n",
                "        return super().call(inputs, training=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now let's create a new model, identical to the one we just trained (with the same weights), but with `MCAlphaDropout` dropout layers instead of `AlphaDropout` layers:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 150,
            "metadata": {},
            "outputs": [],
            "source": [
                "mc_model = keras.models.Sequential([\n",
                "    MCAlphaDropout(layer.rate)\n",
                "    if isinstance(layer, keras.layers.AlphaDropout) else layer\n",
                "    for layer in model.layers\n",
                "])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Then let's add a couple utility functions. The first will run the model many times (10 by default) and it will return the mean predicted class probabilities. The second will use these mean probabilities to predict the most likely class for each instance:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 151,
            "metadata": {},
            "outputs": [],
            "source": [
                "def mc_dropout_predict_probas(mc_model, X, n_samples=10):\n",
                "    Y_probas = [mc_model.predict(X) for sample in range(n_samples)]\n",
                "    return np.mean(Y_probas, axis=0)\n",
                "\n",
                "\n",
                "def mc_dropout_predict_classes(mc_model, X, n_samples=10):\n",
                "    Y_probas = mc_dropout_predict_probas(mc_model, X, n_samples)\n",
                "    return np.argmax(Y_probas, axis=1)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now let's make predictions for all the instances in the validation set, and compute the accuracy:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 152,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0.4912"
                        ]
                    },
                    "execution_count": 152,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "keras.backend.clear_session()\n",
                "tf.random.set_seed(42)\n",
                "np.random.seed(42)\n",
                "\n",
                "y_pred = mc_dropout_predict_classes(mc_model, X_valid_scaled)\n",
                "accuracy = np.mean(y_pred == y_valid[:, 0])\n",
                "accuracy"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We get no accuracy improvement in this case (we're still at 48.9% accuracy).\n",
                "\n",
                "So the best model we got in this exercise is the Batch Normalization model.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### f.\n",
                "\n",
                "_Exercise: Retrain your model using 1cycle scheduling and see if it improves training speed and model accuracy._\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 153,
            "metadata": {},
            "outputs": [],
            "source": [
                "keras.backend.clear_session()\n",
                "tf.random.set_seed(42)\n",
                "np.random.seed(42)\n",
                "\n",
                "model = keras.models.Sequential()\n",
                "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
                "for _ in range(20):\n",
                "    model.add(\n",
                "        keras.layers.Dense(100,\n",
                "                           kernel_initializer=\"lecun_normal\",\n",
                "                           activation=\"selu\"))\n",
                "\n",
                "model.add(keras.layers.AlphaDropout(rate=0.1))\n",
                "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
                "\n",
                "optimizer = keras.optimizers.SGD(learning_rate=1e-3)\n",
                "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
                "              optimizer=optimizer,\n",
                "              metrics=[\"accuracy\"])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 154,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "352/352 [==============================] - 3s 7ms/step - loss: nan - accuracy: 0.1382\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "(9.999999747378752e-06,\n",
                            " 9.615227699279785,\n",
                            " 2.617628335952759,\n",
                            " 4.006586245128087)"
                        ]
                    },
                    "execution_count": 154,
                    "metadata": {},
                    "output_type": "execute_result"
                },
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 432x288 with 1 Axes>"
                        ]
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": [
                "batch_size = 128\n",
                "rates, losses = find_learning_rate(model,\n",
                "                                   X_train_scaled,\n",
                "                                   y_train,\n",
                "                                   epochs=1,\n",
                "                                   batch_size=batch_size)\n",
                "plot_lr_vs_loss(rates, losses)\n",
                "plt.axis(\n",
                "    [min(rates),\n",
                "     max(rates),\n",
                "     min(losses), (losses[0] + min(losses)) / 1.4])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 155,
            "metadata": {},
            "outputs": [],
            "source": [
                "keras.backend.clear_session()\n",
                "tf.random.set_seed(42)\n",
                "np.random.seed(42)\n",
                "\n",
                "model = keras.models.Sequential()\n",
                "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
                "for _ in range(20):\n",
                "    model.add(\n",
                "        keras.layers.Dense(100,\n",
                "                           kernel_initializer=\"lecun_normal\",\n",
                "                           activation=\"selu\"))\n",
                "\n",
                "model.add(keras.layers.AlphaDropout(rate=0.1))\n",
                "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
                "\n",
                "optimizer = keras.optimizers.SGD(learning_rate=1e-2)\n",
                "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
                "              optimizer=optimizer,\n",
                "              metrics=[\"accuracy\"])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 156,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/15\n",
                        "352/352 [==============================] - 3s 8ms/step - loss: 2.0435 - accuracy: 0.2881 - val_loss: 1.7966 - val_accuracy: 0.3826\n",
                        "Epoch 2/15\n",
                        "352/352 [==============================] - 3s 8ms/step - loss: 1.7539 - accuracy: 0.3780 - val_loss: 1.6603 - val_accuracy: 0.4164\n",
                        "Epoch 3/15\n",
                        "352/352 [==============================] - 3s 8ms/step - loss: 1.6132 - accuracy: 0.4295 - val_loss: 1.6760 - val_accuracy: 0.4142\n",
                        "Epoch 4/15\n",
                        "352/352 [==============================] - 3s 8ms/step - loss: 1.5384 - accuracy: 0.4554 - val_loss: 1.5857 - val_accuracy: 0.4388\n",
                        "Epoch 5/15\n",
                        "352/352 [==============================] - 3s 8ms/step - loss: 1.4891 - accuracy: 0.4704 - val_loss: 1.5996 - val_accuracy: 0.4520\n",
                        "Epoch 6/15\n",
                        "352/352 [==============================] - 3s 8ms/step - loss: 1.4489 - accuracy: 0.4878 - val_loss: 1.5266 - val_accuracy: 0.4748\n",
                        "Epoch 7/15\n",
                        "352/352 [==============================] - 3s 8ms/step - loss: 1.4133 - accuracy: 0.4967 - val_loss: 1.6491 - val_accuracy: 0.4400\n",
                        "Epoch 8/15\n",
                        "352/352 [==============================] - 3s 8ms/step - loss: 1.3490 - accuracy: 0.5207 - val_loss: 1.5526 - val_accuracy: 0.4704\n",
                        "Epoch 9/15\n",
                        "352/352 [==============================] - 3s 8ms/step - loss: 1.2774 - accuracy: 0.5460 - val_loss: 1.5128 - val_accuracy: 0.4810\n",
                        "Epoch 10/15\n",
                        "352/352 [==============================] - 3s 8ms/step - loss: 1.2055 - accuracy: 0.5671 - val_loss: 1.5060 - val_accuracy: 0.5008\n",
                        "Epoch 11/15\n",
                        "352/352 [==============================] - 3s 8ms/step - loss: 1.1380 - accuracy: 0.5958 - val_loss: 1.5209 - val_accuracy: 0.5072\n",
                        "Epoch 12/15\n",
                        "352/352 [==============================] - 3s 8ms/step - loss: 1.0699 - accuracy: 0.6184 - val_loss: 1.4874 - val_accuracy: 0.5134\n",
                        "Epoch 13/15\n",
                        "352/352 [==============================] - 3s 8ms/step - loss: 0.9982 - accuracy: 0.6421 - val_loss: 1.5120 - val_accuracy: 0.5176\n",
                        "Epoch 14/15\n",
                        "352/352 [==============================] - 3s 8ms/step - loss: 0.9345 - accuracy: 0.6658 - val_loss: 1.5383 - val_accuracy: 0.5220\n",
                        "Epoch 15/15\n",
                        "352/352 [==============================] - 3s 8ms/step - loss: 0.8942 - accuracy: 0.6799 - val_loss: 1.5702 - val_accuracy: 0.5206\n"
                    ]
                }
            ],
            "source": [
                "n_epochs = 15\n",
                "onecycle = OneCycleScheduler(math.ceil(len(X_train_scaled) / batch_size) *\n",
                "                             n_epochs,\n",
                "                             max_rate=0.05)\n",
                "history = model.fit(X_train_scaled,\n",
                "                    y_train,\n",
                "                    epochs=n_epochs,\n",
                "                    batch_size=batch_size,\n",
                "                    validation_data=(X_valid_scaled, y_valid),\n",
                "                    callbacks=[onecycle])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "One cycle allowed us to train the model in just 15 epochs, each taking only 2 seconds (thanks to the larger batch size). This is several times faster than the fastest model we trained so far. Moreover, we improved the model's performance (from 47.6% to 52.0%). The batch normalized model reaches a slightly better performance (54%), but it's much slower to train.\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.2"
        },
        "nav_menu": {
            "height": "360px",
            "width": "416px"
        },
        "toc": {
            "navigate_menu": true,
            "number_sections": true,
            "sideBar": true,
            "threshold": 6,
            "toc_cell": false,
            "toc_section_display": "block",
            "toc_window_display": false
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
